{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## voice features\n",
    "#### 先对所有的时间进行特征提取\n",
    "1. 用户电话的总的通话次数 opp\n",
    "2. 通话的人数，voice_all_unique_cnt\n",
    "3. 通话次数 / 人数的比例， voice_all_cnt_all_unique_cnt_rate\n",
    "4. 对端电话的前n位的个数，所有的不同号码的个数。 opp_head\n",
    "5. 对端号码长度的分布个数   opp_len\n",
    "6. 通话最大时长，平均时长，最小时长，极差时长等统计的信息  start_time, end_time\n",
    "7. 通话类型的分布个数或者比例 call_type\n",
    "8. 通话类型的分布个数和比例   in_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_voice = pd.read_csv('../data/train/voice_train.txt',sep='\\t',low_memory=False)\n",
    "df_train_label = pd.read_csv('../data/train/uid_train.txt',sep='\\t',low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1150778 entries, 0 to 1150777\n",
      "Data columns (total 17 columns):\n",
      "uid                  1150778 non-null object\n",
      "opp_num              1150778 non-null object\n",
      "opp_head             1150778 non-null object\n",
      "opp_len              1150778 non-null int64\n",
      "start_time           1150778 non-null int64\n",
      "end_time             1150778 non-null int64\n",
      "call_type            1150778 non-null int64\n",
      "in_out               1150778 non-null int64\n",
      "start_time_day       1150778 non-null int64\n",
      "start_time_hour      1150778 non-null int64\n",
      "start_time_minute    1150778 non-null int64\n",
      "start_time_second    1150778 non-null int64\n",
      "end_time_day         1150778 non-null int64\n",
      "end_time_hour        1150778 non-null int64\n",
      "end_time_minute      1150778 non-null int64\n",
      "end_time_second      1150778 non-null int64\n",
      "diff_time            1150778 non-null int64\n",
      "dtypes: int64(14), object(3)\n",
      "memory usage: 149.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>opp_num</th>\n",
       "      <th>opp_head</th>\n",
       "      <th>opp_len</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>call_type</th>\n",
       "      <th>in_out</th>\n",
       "      <th>start_time_day</th>\n",
       "      <th>start_time_hour</th>\n",
       "      <th>start_time_minute</th>\n",
       "      <th>start_time_second</th>\n",
       "      <th>end_time_day</th>\n",
       "      <th>end_time_hour</th>\n",
       "      <th>end_time_minute</th>\n",
       "      <th>end_time_second</th>\n",
       "      <th>diff_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u0113</td>\n",
       "      <td>38D54642A237A11BB18455FC1E505292</td>\n",
       "      <td>132</td>\n",
       "      <td>11</td>\n",
       "      <td>26115956</td>\n",
       "      <td>26120033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>59</td>\n",
       "      <td>56</td>\n",
       "      <td>26</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>u0113</td>\n",
       "      <td>38D54642A237A11BB18455FC1E505292</td>\n",
       "      <td>132</td>\n",
       "      <td>11</td>\n",
       "      <td>26115623</td>\n",
       "      <td>26115707</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>56</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>u0113</td>\n",
       "      <td>38D54642A237A11BB18455FC1E505292</td>\n",
       "      <td>132</td>\n",
       "      <td>11</td>\n",
       "      <td>26174233</td>\n",
       "      <td>26174321</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "      <td>43</td>\n",
       "      <td>21</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u0113</td>\n",
       "      <td>38D54642A237A11BB18455FC1E505292</td>\n",
       "      <td>132</td>\n",
       "      <td>11</td>\n",
       "      <td>26070423</td>\n",
       "      <td>26070512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>u3340</td>\n",
       "      <td>010A66F2AD42C48C44897A3DEC96A2A1</td>\n",
       "      <td>139</td>\n",
       "      <td>11</td>\n",
       "      <td>26201745</td>\n",
       "      <td>26201825</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>17</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "      <td>18</td>\n",
       "      <td>25</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     uid                           opp_num opp_head  opp_len  start_time  \\\n",
       "0  u0113  38D54642A237A11BB18455FC1E505292      132       11    26115956   \n",
       "1  u0113  38D54642A237A11BB18455FC1E505292      132       11    26115623   \n",
       "2  u0113  38D54642A237A11BB18455FC1E505292      132       11    26174233   \n",
       "3  u0113  38D54642A237A11BB18455FC1E505292      132       11    26070423   \n",
       "4  u3340  010A66F2AD42C48C44897A3DEC96A2A1      139       11    26201745   \n",
       "\n",
       "   end_time  call_type  in_out  start_time_day  start_time_hour  \\\n",
       "0  26120033          1       1              26               11   \n",
       "1  26115707          1       1              26               11   \n",
       "2  26174321          1       1              26               17   \n",
       "3  26070512          1       0              26                7   \n",
       "4  26201825          1       1              26               20   \n",
       "\n",
       "   start_time_minute  start_time_second  end_time_day  end_time_hour  \\\n",
       "0                 59                 56            26             12   \n",
       "1                 56                 23            26             11   \n",
       "2                 42                 33            26             17   \n",
       "3                  4                 23            26              7   \n",
       "4                 17                 45            26             20   \n",
       "\n",
       "   end_time_minute  end_time_second  diff_time  \n",
       "0                0               33         37  \n",
       "1               57                7         44  \n",
       "2               43               21         48  \n",
       "3                5               12         49  \n",
       "4               18               25         40  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_voice.info()\n",
    "df_train_voice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voice_feature_plus(df_train_voice, target='train'):\n",
    "    if target == 'train':\n",
    "        # 复制lable的数据，作为所有的特征的标示\n",
    "        df_train = df_train_label.copy()\n",
    "    else:\n",
    "        df_train = pd.DataFrame(data={'uid':['u'+str(id) for id in range(5000, 7000)]})\n",
    "    \n",
    "    \n",
    "    df_train_voice['start_time_day'] = df_train_voice['start_time'].apply(lambda x: x / 1000000)\n",
    "    df_train_voice['start_time_hour'] = df_train_voice['start_time'].apply(lambda x: x / 10000 % 100)\n",
    "    df_train_voice['start_time_minute'] = df_train_voice['start_time'].apply(lambda x: x / 100 % 100)\n",
    "    df_train_voice['start_time_second'] = df_train_voice['start_time'].apply(lambda x: x % 100)\n",
    "\n",
    "    df_train_voice['end_time_day'] = df_train_voice['end_time'].apply(lambda x: x / 1000000)\n",
    "    df_train_voice['end_time_hour'] = df_train_voice['end_time'].apply(lambda x: x / 10000 % 100)\n",
    "    df_train_voice['end_time_minute'] = df_train_voice['end_time'].apply(lambda x: x / 100 % 100)\n",
    "    df_train_voice['end_time_second'] = df_train_voice['end_time'].apply(lambda x: x % 100)\n",
    "\n",
    "\n",
    "    df_train_voice['diff_time'] = get_diff_time(df_train_voice[['start_time','end_time']].values)\n",
    "    \n",
    "    \n",
    "    # 总的通话次数\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_num'].count())\n",
    "    df_tmp.columns = ['voice_all_cnt']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # 总的通话的对端的不重复的个数\n",
    "    tmp = df_train_voice.groupby('uid',as_index=True)['opp_num'].unique()\n",
    "    uids = tmp.index\n",
    "    opp_nums = []\n",
    "    for opp_num in tmp:\n",
    "        opp_nums.append(len(opp_num))\n",
    "    df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_unique_cnt':opp_nums})\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # 通话次数 / 人数的比例，每个人通话的次数， voice_all_per_opp_rate\n",
    "    df_train['voice_all_per_opp_rate'] = df_train['voice_all_cnt'] / df_train['voice_all_unique_cnt']\n",
    "    \n",
    "    \n",
    "    # 4. 对端电话的前n位的个数，所有的不同号码的个数以及其所有的分布个数和比例(部分特征待定)。 opp_head_cnt_{k}, opp_head_rate_{k}\n",
    "    # 全部的不同开头的次数,唯一的标示\n",
    "    tmp = df_train_voice.groupby('uid',as_index=True)['opp_head'].unique()\n",
    "    uids = tmp.index\n",
    "    opp_nums = []\n",
    "    for opp_num in tmp:\n",
    "        opp_nums.append(len(opp_num))\n",
    "    df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_head_unique_cnt':opp_nums})\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # 联系最多和最少的次数的opp_head\n",
    "    tmp = df_train_voice.groupby('uid',as_index=True)['opp_head']\n",
    "    voice_all_opp_head_many_head = []\n",
    "    voice_all_opp_head_many_head_cnt = []\n",
    "    voice_all_opp_head_little_head = []\n",
    "#     voice_all_opp_head_little_head_cnt = []\n",
    "    \n",
    "    uids = []\n",
    "    for uid, values in tmp:\n",
    "        uids.append(uid)\n",
    "        voice_all_opp_head_many_head.append(values.value_counts().index[0])\n",
    "        voice_all_opp_head_little_head.append(values.value_counts().index[-1])\n",
    "\n",
    "        voice_all_opp_head_many_head_cnt.append(values.value_counts().values[0])\n",
    "#         voice_all_opp_head_little_head_cnt.append(values.value_counts().values[-1])\n",
    "        \n",
    "\n",
    "    df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_head_many_head':voice_all_opp_head_many_head, \n",
    "                                'voice_all_opp_head_little_head':voice_all_opp_head_little_head,\n",
    "                                'voice_all_opp_head_many_head_cnt':voice_all_opp_head_many_head_cnt})\n",
    "    \n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    df_train['voice_all_opp_head_many_head_cnt_rate'] = df_train['voice_all_opp_head_many_head_cnt'] / df_train['voice_all_cnt']\n",
    "    df_train['voice_all_opp_head_many_head_cnt_rate_unique'] = df_train['voice_all_opp_head_many_head_cnt'] / df_train['voice_all_unique_cnt']\n",
    "    \n",
    "    # 通话最多的head的个数\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_len'].value_counts().unstack())[[3,5,6,7,8,9,10,11,12,13,14,15,16,17,19,20]]\n",
    "    df_tmp.columns = ['voice_all_opp_len_'+str(k) for k in [3,5,6,7,8,9,10,11,12,13,14,15,16,17,19,20]]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    df_train['voice_all_opp_len_11_rate'] = df_train['voice_all_opp_len_11'] / df_train['voice_all_cnt']\n",
    "    \n",
    "    # 最近一次通话的号码的长度\n",
    "    tmp = df_train_voice.groupby('uid',as_index=True)['opp_len']\n",
    "    voice_all_opp_len_many_head = []\n",
    "    voice_all_opp_len_little_head = []\n",
    "    \n",
    "    uids = []\n",
    "    for uid, values in tmp:\n",
    "        uids.append(uid)\n",
    "        voice_all_opp_len_many_head.append(values.value_counts().index[0])\n",
    "        voice_all_opp_len_little_head.append(values.value_counts().index[-1])        \n",
    "    \n",
    "    df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_len_many_head':voice_all_opp_len_many_head, \n",
    "                                'voice_all_opp_len_little_head':voice_all_opp_len_little_head})\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # call_type 分布\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['call_type'].value_counts().unstack()\n",
    "    df_tmp.columns = ['voice_all_call_type_'+str(i) for i in range(1,6)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # call_type 的比例\n",
    "    for feat in ['voice_all_call_type_'+str(i) for i in range(1,6)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "    \n",
    "    # in_out 分布\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['in_out'].value_counts().unstack()\n",
    "    df_tmp.columns = ['voice_all_in_out_'+str(i) for i in range(2)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # in_out 的比例\n",
    "    for feat in ['voice_all_in_out_'+str(i) for i in range(2)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "\n",
    "    \n",
    "    # 处理是假相关的特征，目标100维\n",
    "    # 6. 通话最大时长，平均时长，最小时长，极差时长等统计的信息  start_time, end_time, diff_time\n",
    "    \n",
    "    # day的分布，和比例，注意天的粒度很大，只需使用start end一种即可\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['start_time_day'].value_counts().unstack()[[i for i in range(1,46)]]\n",
    "    df_tmp.columns = ['voice_all_start_end_time_day_'+str(i) for i in range(1,46)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_start_end_time_day_'+str(i) for i in range(1,46)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "    \n",
    "    # hour分布， 我们认为电话时间超过一小时可能是有问题的，所以使用两种\n",
    "    # start_time_hour\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['start_time_hour'].value_counts().unstack()[[i for i in range(0,24)]]\n",
    "    df_tmp.columns = ['voice_all_start_time_hour_'+str(i) for i in range(24)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_start_time_hour_'+str(i) for i in range(0,24)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "    \n",
    "    # end_time_hour\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['end_time_hour'].value_counts().unstack()[[i for i in range(0,24)]]\n",
    "    df_tmp.columns = ['voice_all_end_time_hour_'+str(i) for i in range(24)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_end_time_hour_'+str(i) for i in range(0,24)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "    \n",
    "    \n",
    "    # minute 分布\n",
    "    # start_time_minute\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['start_time_minute'].value_counts().unstack()[[i for i in range(0,60)]]\n",
    "    df_tmp.columns = ['voice_all_start_time_minute_'+str(i) for i in range(60)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_start_time_minute_'+str(i) for i in range(60)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "\n",
    "    # end_time_minute\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['end_time_minute'].value_counts().unstack()[[i for i in range(0,60)]]\n",
    "    df_tmp.columns = ['voice_all_end_time_minute_'+str(i) for i in range(60)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_end_time_minute_'+str(i) for i in range(60)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "\n",
    "\n",
    "    # second 分布\n",
    "    # start_time_second\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['start_time_second'].value_counts().unstack()[[i for i in range(0,60)]]\n",
    "    df_tmp.columns = ['voice_all_start_time_second_'+str(i) for i in range(60)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_start_time_second_'+str(i) for i in range(60)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "\n",
    "    # end_time_minute\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['end_time_second'].value_counts().unstack()[[i for i in range(0,60)]]\n",
    "    df_tmp.columns = ['voice_all_end_time_second_'+str(i) for i in range(60)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    for feat in ['voice_all_end_time_second_'+str(i) for i in range(60)]:\n",
    "        df_train[feat+'_rate'] = df_train[feat] / df_train['voice_all_cnt']\n",
    "    \n",
    "    \n",
    "    # diff_time\n",
    "    # sum \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].sum())\n",
    "    df_tmp.columns = ['voice_all_diff_time_sum']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # meam\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].mean())\n",
    "    df_tmp.columns = ['voice_all_diff_time_avg']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # max\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].max())\n",
    "    df_tmp.columns = ['voice_all_diff_time_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # min\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].min())\n",
    "    df_tmp.columns = ['voice_all_diff_time_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # std\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].std())\n",
    "    df_tmp.columns = ['voice_all_diff_time_std']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # skew \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].skew())\n",
    "    df_tmp.columns = ['voice_all_diff_time_skew']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    df_train['voice_all_diff_time_jc'] = df_train['voice_all_diff_time_max'] - df_train['voice_all_diff_time_min']\n",
    "    df_train['voice_all_diff_time_fd'] = df_train['voice_all_diff_time_std'] / df_train['voice_all_diff_time_avg']\n",
    "\n",
    "    # start_time_first, start_time_last, end_time_first, end_time_last, 以及对应的差值， 以及差值 / 总的次数\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].max())\n",
    "    df_tmp.columns = ['voice_all_start_time_last']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].min())\n",
    "    df_tmp.columns = ['voice_all_start_time_first']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].max())\n",
    "    df_tmp.columns = ['voice_all_end_time_last']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].min())\n",
    "    df_tmp.columns = ['voice_all_end_time_first']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # start_time_last - start_time_first,\n",
    "    # end_time_last - end_time_first,    \n",
    "    # end_time_first - start_time_first,\n",
    "    # end_time_last - start_time_last,\n",
    "    df_train['voice_all_start_time_last_start_time_first_diff'] = get_diff_time(df_train[['voice_all_start_time_first','voice_all_start_time_last']].values)\n",
    "    df_train['voice_all_end_time_last_end_time_first_diff'] = get_diff_time(df_train[['voice_all_end_time_first','voice_all_end_time_last']].values)\n",
    "    df_train['voice_all_end_time_first_start_time_first_diff'] = get_diff_time(df_train[['voice_all_end_time_first','voice_all_start_time_first']].values)\n",
    "    df_train['voice_all_end_time_last_start_time_last_diff'] = get_diff_time(df_train[['voice_all_end_time_last','voice_all_start_time_last']].values)\n",
    "    \n",
    "    # 平均多久打一次电话\n",
    "    df_train['voice_all_end_time_first_start_time_first_diff_rate'] = df_train['voice_all_end_time_first_start_time_first_diff'] / df_train['voice_all_cnt']\n",
    "    df_train['voice_all_end_time_last_start_time_last_diff_rate'] = df_train['voice_all_end_time_last_start_time_last_diff'] / df_train['voice_all_cnt']\n",
    "    \n",
    "    # 待定对所有的start_time, end_time进行统计信息\n",
    "    # start_time\n",
    "    # sum \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].sum())\n",
    "    df_tmp.columns = ['voice_all_start_time_sum']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # meam\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].mean())\n",
    "    df_tmp.columns = ['voice_all_start_time_avg']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # max\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].max())\n",
    "    df_tmp.columns = ['voice_all_start_time_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # min\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].min())\n",
    "    df_tmp.columns = ['voice_all_start_time_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # std\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].std())\n",
    "    df_tmp.columns = ['voice_all_start_time_std']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # skew \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].skew())\n",
    "    df_tmp.columns = ['voice_all_start_time_skew']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_train['voice_all_start_time_jc'] = df_train['voice_all_start_time_max'] - df_train['voice_all_start_time_min']\n",
    "    df_train['voice_all_start_time_fd'] = df_train['voice_all_start_time_std'] / df_train['voice_all_start_time_avg']\n",
    "\n",
    "    # end_timne\n",
    "    # sum \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].sum())\n",
    "    df_tmp.columns = ['voice_all_end_time_sum']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # meam\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].mean())\n",
    "    df_tmp.columns = ['voice_all_end_time_avg']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # max\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].max())\n",
    "    df_tmp.columns = ['voice_all_end_time_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # min\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].min())\n",
    "    df_tmp.columns = ['voice_all_end_time_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # std\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].std())\n",
    "    df_tmp.columns = ['voice_all_end_time_std']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # skew \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].skew())\n",
    "    df_tmp.columns = ['voice_all_end_time_skew']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_train['voice_all_end_time_jc'] = df_train['voice_all_end_time_max'] - df_train['voice_all_end_time_min']\n",
    "    df_train['voice_all_end_time_fd'] = df_train['voice_all_end_time_std'] / df_train['voice_all_end_time_avg']\n",
    "                      \n",
    "    return df_train\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_voice_feature(df_train_voice, target='train'):\n",
    "    if target == 'train':\n",
    "        # 复制lable的数据，作为所有的特征的标示\n",
    "        df_train = df_train_label.copy()\n",
    "    else:\n",
    "        tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['uid'].count())\n",
    "        df_train = pd.DataFrame(data={'uid':tmp.index})\n",
    "    \n",
    "    tmp = df_train_voice.groupby('uid',as_index=True)['opp_num'].unique()\n",
    "    uids = tmp.index\n",
    "    opp_nums = []\n",
    "    for opp_num in tmp:\n",
    "        opp_nums.append(len(opp_num))\n",
    "\n",
    "    df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_num_unique_cnt':opp_nums})\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_num'].count())\n",
    "    df_tmp.columns = ['voice_all_opp_num_cnt']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # 通话次数 / 通话的人数\n",
    "    df_train['voice_opp_num_all_cnt_unique_cnt_rate'] = df_train['voice_all_opp_num_cnt'] / df_train['voice_all_opp_num_unique_cnt']\n",
    "\n",
    "    \n",
    "    # 全部的不同开头的次数,唯一的标示\n",
    "    tmp = df_train_voice.groupby('uid',as_index=True)['opp_head'].unique()\n",
    "    uids = tmp.index\n",
    "    opp_nums = []\n",
    "    for opp_num in tmp:\n",
    "        opp_nums.append(len(opp_num))\n",
    "\n",
    "    df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_head_unique_cnt':opp_nums})\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # 通话次数 / opp_len的次数\n",
    "    df_train['voice_opp_head_all_cnt_unique_cnt_rate'] = df_train['voice_all_opp_num_cnt'] / df_train['voice_all_opp_head_unique_cnt']\n",
    "\n",
    "    # 通话最多的head的个数，\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_head'].value_counts().unstack().max(axis=1))\n",
    "    df_tmp.columns = ['voice_all_opp_head_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "\n",
    "    # 通话最小的head的个数，\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_head'].value_counts().unstack().min(axis=1))\n",
    "    df_tmp.columns = ['voice_all_opp_head_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # 极差，和占总个比例\n",
    "    df_train['voice_all_opp_head_jc'] = df_train['voice_all_opp_head_max'] - df_train['voice_all_opp_head_min']\n",
    "    df_train['voice_opp_head_all_max_rate'] = df_train['voice_all_opp_head_max'] / df_train['voice_all_opp_num_cnt']\n",
    "\n",
    "    \n",
    "    # call_type 分布\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['call_type'].value_counts().unstack()\n",
    "    df_tmp.columns = ['voice_all_call_type_'+str(i) for i in range(1,6)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # call_type 分布\n",
    "    df_tmp = df_train_voice.groupby('uid',as_index=True)['in_out'].value_counts().unstack()\n",
    "\n",
    "    df_tmp.columns = ['voice_all_in_out_'+str(i) for i in range(2)]\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_tmp.fillna(0,inplace=True)\n",
    "\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # diff_time\n",
    "    df_train_voice['diff_time'] = df_train_voice['end_time'] - df_train_voice['start_time']\n",
    "\n",
    "    # sum \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].sum())\n",
    "    df_tmp.columns = ['voice_all_diff_time_sum']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # meam\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].mean())\n",
    "    df_tmp.columns = ['voice_all_diff_time_avg']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # max\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].max())\n",
    "    df_tmp.columns = ['voice_all_diff_time_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # min\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].min())\n",
    "    df_tmp.columns = ['voice_all_diff_time_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # std\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].std())\n",
    "    df_tmp.columns = ['voice_all_diff_time_std']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # skew \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['diff_time'].skew())\n",
    "    df_tmp.columns = ['voice_all_diff_time_skew']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_train['voice_all_diff_time_jc'] = df_train['voice_all_diff_time_max'] - df_train['voice_all_diff_time_min']\n",
    "    df_train['voice_all_diff_time_fd'] = df_train['voice_all_diff_time_std'] / df_train['voice_all_diff_time_avg']\n",
    "\n",
    "    # sum \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].sum())\n",
    "    df_tmp.columns = ['voice_all_start_time_sum']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # meam\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].mean())\n",
    "    df_tmp.columns = ['voice_all_start_time_avg']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # max\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].max())\n",
    "    df_tmp.columns = ['voice_all_start_time_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # min\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].min())\n",
    "    df_tmp.columns = ['voice_all_start_time_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # std\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].std())\n",
    "    df_tmp.columns = ['voice_all_start_time_std']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # skew \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['start_time'].skew())\n",
    "    df_tmp.columns = ['voice_all_start_time_skew']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_train['voice_all_start_time_jc'] = df_train['voice_all_start_time_max'] - df_train['voice_all_start_time_min']\n",
    "    df_train['voice_all_start_time_fd'] = df_train['voice_all_start_time_std'] / df_train['voice_all_start_time_avg']\n",
    "\n",
    "        # sum \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].sum())\n",
    "    df_tmp.columns = ['voice_all_end_time_sum']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    # meam\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].mean())\n",
    "    df_tmp.columns = ['voice_all_end_time_avg']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "    # max\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].max())\n",
    "    df_tmp.columns = ['voice_all_end_time_max']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # min\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].min())\n",
    "    df_tmp.columns = ['voice_all_end_time_min']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # std\n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].std())\n",
    "    df_tmp.columns = ['voice_all_end_time_std']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    # skew \n",
    "    df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['end_time'].skew())\n",
    "    df_tmp.columns = ['voice_all_end_time_skew']\n",
    "    df_tmp['uid'] = df_tmp.index\n",
    "    df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "    df_train['voice_all_end_time_jc'] = df_train['voice_all_end_time_max'] - df_train['voice_all_end_time_min']\n",
    "    df_train['voice_all_end_time_fd'] = df_train['voice_all_end_time_std'] / df_train['voice_all_end_time_avg']\n",
    "\n",
    "    \n",
    "    return df_train\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_time(a,b):\n",
    "    a_day, a_hour, a_minute, a_second = (a / 1000000, a / 10000 % 100, a / 100 % 100, a % 100)\n",
    "    b_day, b_hour, b_minute, b_second = (b / 1000000, b / 10000 % 100, b / 100 % 100, b % 100)\n",
    "    \n",
    "    d_day = b_day - a_day\n",
    "    d_hour = b_hour - a_hour\n",
    "    d_minute = b_minute - a_minute\n",
    "    d_second = b_second - a_second\n",
    "    \n",
    "    diff = d_day * 24 * 60 * 60 + d_hour * 60 * 60 + d_minute * 60 + d_second\n",
    "    return diff\n",
    "\n",
    "def get_diff_time(x):\n",
    "    diff_t = []\n",
    "    for d in x:\n",
    "#         print d\n",
    "        diff_t.append(diff_time(d[0],d[1]))\n",
    "    return diff_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test_voice = pd.read_csv('../data/test/voice_test_a.txt',sep='\\t',low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_voice['opp_len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = get_voice_feature_plus(df_test_voice, target='test')\n",
    "df_train = get_voice_feature_plus(df_train_voice)\n",
    "\n",
    "df_test['voice_all_opp_head_unique_cnt'] = df_test['voice_all_opp_head_unique_cnt'].astype(float)\n",
    "df_test['voice_all_opp_head_many_head'] = df_test['voice_all_opp_head_many_head'].astype(float)\n",
    "df_train['voice_all_opp_head_little_head'] = df_train['voice_all_opp_head_little_head'].astype(int)\n",
    "df_train['voice_all_opp_head_many_head'] = df_train['voice_all_opp_head_many_head'].astype(int)\n",
    "\n",
    "df_train.fillna(0,inplace=True)\n",
    "df_test.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_valid = df_train.sample(n=300, replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2000 entries, 0 to 1999\n",
      "Columns: 743 entries, uid to voice_all_end_time_fd\n",
      "dtypes: float64(742), object(1)\n",
      "memory usage: 11.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4999 entries, 0 to 4998\n",
      "Columns: 744 entries, uid to voice_all_end_time_fd\n",
      "dtypes: float64(740), int64(3), object(1)\n",
      "memory usage: 28.4+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_train['voice_all_opp_head_little_head'] = df_train['voice_all_opp_head_little_head'].astype(int)\n",
    "df_train['voice_all_opp_head_many_head'] = df_train['voice_all_opp_head_many_head'].astype(int)\n",
    "df_test.info()\n",
    "\n",
    "df_train.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 71\n",
    "\n",
    "np.random.seed(seed)\n",
    "valid_size = 0.2\n",
    "LOOP = 1\n",
    "ESR = 50\n",
    "# XGB param\n",
    "nround = 3000\n",
    "#nround = 10\n",
    "\n",
    "param = {'max_depth':5, # 基准是5 \n",
    "         'eta':0.05,\n",
    "         'gamma ':0.1,\n",
    "         'colsample_bytree':0.8, # old 0.8\n",
    "         'subsample':0.8,\n",
    "         'silent':1,\n",
    "         'eval_metric':'auc',\n",
    "         'objective':'binary:logistic',\n",
    "#          'scale_pos_weight':5,\n",
    "         'seed': seed\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "742\n"
     ]
    }
   ],
   "source": [
    "# 设置特征数据，去除id数据，不能进行预测\n",
    "features = df_test.columns\n",
    "features = list(features)\n",
    "features.remove('uid')\n",
    "\n",
    "label = 'label'\n",
    "\n",
    "print len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_valid(df_train,test_size=0.2):\n",
    "    '''\n",
    "    k-fold交叉验证,默认k=10\n",
    "    df_train:训练数据\n",
    "    '''\n",
    "    X_train, X_vali, y_train, y_vali = train_test_split(df_train[features], df_train[label], test_size=test_size, random_state=40000)\n",
    "    #added some parameters\n",
    "    \n",
    "#     dtrain = df_train.iloc[train_list]\n",
    "#     dvali =  df_train.iloc[vali_list]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_vali,label=y_vali)\n",
    "    watchlist = [(dtrain, 'train'),(dvalid, 'valid')]\n",
    "    \n",
    "    return dtrain, dvalid, watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LOOP', 0)\n",
      "[0]\ttrain-auc:0.824913\tvalid-auc:0.801899\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 50 rounds.\n",
      "[20]\ttrain-auc:0.913341\tvalid-auc:0.838544\n",
      "[40]\ttrain-auc:0.946254\tvalid-auc:0.84396\n",
      "[60]\ttrain-auc:0.968482\tvalid-auc:0.849129\n",
      "[80]\ttrain-auc:0.982766\tvalid-auc:0.848944\n",
      "[100]\ttrain-auc:0.991236\tvalid-auc:0.851752\n",
      "[120]\ttrain-auc:0.994963\tvalid-auc:0.852864\n",
      "[140]\ttrain-auc:0.997341\tvalid-auc:0.853083\n",
      "Stopping. Best iteration:\n",
      "[107]\ttrain-auc:0.992645\tvalid-auc:0.853907\n",
      "\n",
      "('Valid Mean:---------------------->', 0.16489457)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "seeds = [71,73,91]\n",
    "for i in range(LOOP):\n",
    "    print('LOOP',i)\n",
    "#     dbuild, dvalid, watchlist = split_build_valid(df_train)\n",
    "    dbuild, dvalid, watchlist = split_train_valid(df_train,test_size=0.2)\n",
    "    param['seed'] = seeds[i]\n",
    "    model = xgb.train(param, dbuild, nround, watchlist,early_stopping_rounds=ESR,verbose_eval=20)\n",
    "    models.append(model)\n",
    "#     model.save_model('./model1'+ str(i) + '.model')\n",
    "    # VALID\n",
    "    valid_yhat = model.predict(dvalid,ntree_limit=model.best_iteration)\n",
    "    print('Valid Mean:---------------------->', np.mean(valid_yhat))\n",
    "    del dbuild, dvalid, watchlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dvalid  = xgb.DMatrix(df_valid[features])\n",
    "proba_test = pd.DataFrame()\n",
    "proba_test['uid'] = df_valid['uid']\n",
    "proba_test['score'] = [0 for i in range(len(df_valid))]\n",
    "for model in models:\n",
    "    proba_test['score'] += model.predict(dvalid)\n",
    "proba_test['score'] /= LOOP\n",
    "\n",
    "proba_test = proba_test.sort_values('score',ascending=False)\n",
    "proba_test['label'] = [0 for i in range(len(proba_test))]\n",
    "\n",
    "proba_test.loc[proba_test['score']>0.2, 'label'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_score(pre_result, real_result):\n",
    "    '''\n",
    "    score = 0.6 * acu + 0.4 * F1\n",
    "    :param pre_result:\n",
    "    :param real_result:\n",
    "    :return:\n",
    "    '''\n",
    "    print len(real_result['label'].values)\n",
    "    print len(pre_result['score'].values)\n",
    "    auc = roc_auc_score(real_result['label'].values, pre_result['score'].values)\n",
    "    f1 = f1_score(real_result['label'], pre_result['label'])\n",
    "    score = 0.6 * auc + 0.4 * f1\n",
    "    print \"auc = %f, f1 = %f, score = %f\" % (auc, f1, score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_score(proba_test, df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtest  = xgb.DMatrix(df_test[features])\n",
    "proba_test = pd.DataFrame()\n",
    "proba_test['uid'] = df_test['uid']\n",
    "proba_test['score'] = [0 for i in range(len(df_test))]\n",
    "for model in models:\n",
    "    proba_test['score'] += model.predict(dtest)\n",
    "proba_test['score'] /= LOOP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test = proba_test.sort_values('score',ascending=False)\n",
    "proba_test['label'] = [0 for i in range(len(proba_test))]\n",
    "\n",
    "proba_test.loc[proba_test['score']>0.28, 'label'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1537\n",
       "1     463\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proba_test['label'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_test[['uid','label']].to_csv('../result/result2.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(['u'+str(i) for i in range(5000,7000)]) - set(proba_test.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('voice_all_opp_len_12', 81), ('voice_all_opp_len_15', 48), ('voice_all_in_out_0_rate', 47), ('voice_all_opp_head_many_head_cnt_rate', 40), ('voice_all_start_time_first', 31), ('voice_all_start_time_hour_8_rate', 30), ('voice_all_per_opp_rate', 30), ('voice_all_start_time_hour_7', 28), ('voice_all_end_time_hour_7_rate', 27), ('voice_all_opp_head_many_head', 25), ('voice_all_opp_head_many_head_cnt_rate_unique', 24), ('voice_all_start_time_hour_7_rate', 24), ('voice_all_start_end_time_day_39_rate', 24), ('voice_all_start_time_minute_29_rate', 22), ('voice_all_call_type_3', 22), ('voice_all_unique_cnt', 21), ('voice_all_start_time_hour_21_rate', 21), ('voice_all_start_time_last', 20), ('voice_all_opp_len_8', 20), ('voice_all_diff_time_max', 19), ('voice_all_start_end_time_day_25_rate', 18), ('voice_all_call_type_1_rate', 18), ('voice_all_start_time_hour_11_rate', 17), ('voice_all_start_time_std', 17), ('voice_all_end_time_first', 17), ('voice_all_diff_time_avg', 16), ('voice_all_start_time_minute_49_rate', 16), ('voice_all_call_type_3_rate', 15), ('voice_all_start_end_time_day_26_rate', 15), ('voice_all_opp_len_11_rate', 15), ('voice_all_end_time_hour_11_rate', 15), ('voice_all_opp_len_5', 15), ('voice_all_end_time_minute_9_rate', 14), ('voice_all_start_time_minute_51_rate', 14), ('voice_all_in_out_1_rate', 13), ('voice_all_start_end_time_day_34_rate', 13), ('voice_all_start_time_minute_18_rate', 13), ('voice_all_opp_head_little_head', 13), ('voice_all_start_time_hour_22_rate', 13), ('voice_all_end_time_second_19_rate', 12), ('voice_all_start_time_second_32_rate', 12), ('voice_all_start_time_skew', 12), ('voice_all_end_time_hour_7', 12), ('voice_all_opp_len_10', 12), ('voice_all_end_time_second_49_rate', 12), ('voice_all_end_time_minute_13_rate', 11), ('voice_all_end_time_second_54_rate', 11), ('voice_all_end_time_second_57_rate', 11), ('voice_all_start_time_hour_17_rate', 11), ('voice_all_end_time_minute_6_rate', 11), ('voice_all_opp_len_little_head', 11), ('voice_all_end_time_second_51_rate', 11), ('voice_all_start_time_second_22_rate', 10), ('voice_all_start_time_avg', 10), ('voice_all_start_time_hour_15_rate', 10), ('voice_all_end_time_minute_20_rate', 10), ('voice_all_start_time_second_9_rate', 10), ('voice_all_start_time_hour_16_rate', 10), ('voice_all_end_time_hour_0_rate', 10), ('voice_all_start_time_second_51_rate', 10), ('voice_all_end_time_last_start_time_last_diff', 10), ('voice_all_end_time_hour_8_rate', 10), ('voice_all_start_time_hour_10_rate', 10), ('voice_all_end_time_minute_43_rate', 10), ('voice_all_start_time_minute_5_rate', 10), ('voice_all_start_time_fd', 10), ('voice_all_start_time_hour_6_rate', 10), ('voice_all_start_time_hour_14_rate', 9), ('voice_all_diff_time_min', 9), ('voice_all_start_time_last_start_time_first_diff', 9), ('voice_all_start_time_minute_56_rate', 9), ('voice_all_start_end_time_day_16_rate', 9), ('voice_all_start_end_time_day_37_rate', 9), ('voice_all_start_time_hour_12_rate', 9), ('voice_all_start_time_minute_31_rate', 9), ('voice_all_end_time_minute_23_rate', 9), ('voice_all_start_end_time_day_24_rate', 9), ('voice_all_diff_time_fd', 9), ('voice_all_start_time_minute_12_rate', 9), ('voice_all_start_end_time_day_32_rate', 8), ('voice_all_start_end_time_day_19_rate', 8), ('voice_all_call_type_2_rate', 8), ('voice_all_start_end_time_day_42_rate', 8), ('voice_all_end_time_first_start_time_first_diff_rate', 8), ('voice_all_start_end_time_day_20_rate', 8), ('voice_all_end_time_minute_55_rate', 8), ('voice_all_start_time_sum', 8), ('voice_all_end_time_first_start_time_first_diff', 8), ('voice_all_start_time_second_1_rate', 8), ('voice_all_end_time_minute_41_rate', 8), ('voice_all_end_time_hour_16_rate', 8), ('voice_all_start_time_hour_19_rate', 8), ('voice_all_end_time_minute_46_rate', 8), ('voice_all_end_time_minute_40_rate', 8), ('voice_all_start_end_time_day_21_rate', 8), ('voice_all_start_time_second_18_rate', 8), ('voice_all_start_time_hour_9_rate', 7), ('voice_all_start_end_time_day_40_rate', 7), ('voice_all_start_time_second_53_rate', 7), ('voice_all_start_time_minute_55_rate', 7), ('voice_all_start_end_time_day_8_rate', 7), ('voice_all_start_time_second_13_rate', 7), ('voice_all_end_time_second_0_rate', 7), ('voice_all_start_time_minute_10_rate', 7), ('voice_all_end_time_hour_22', 7), ('voice_all_end_time_hour_22_rate', 7), ('voice_all_start_time_minute_59_rate', 7), ('voice_all_start_time_second_28_rate', 7), ('voice_all_end_time_minute_1_rate', 7), ('voice_all_end_time_hour_17_rate', 7), ('voice_all_end_time_second_59_rate', 7), ('voice_all_start_time_minute_19_rate', 7), ('voice_all_start_time_minute_11_rate', 7), ('voice_all_start_end_time_day_2_rate', 7), ('voice_all_end_time_second_1_rate', 7), ('voice_all_end_time_hour_13_rate', 7), ('voice_all_end_time_second_23_rate', 7), ('voice_all_end_time_second_24_rate', 7), ('voice_all_start_time_minute_53_rate', 7), ('voice_all_end_time_second_35_rate', 7), ('voice_all_end_time_second_39_rate', 7), ('voice_all_end_time_minute_48_rate', 6), ('voice_all_start_end_time_day_14', 6), ('voice_all_start_time_hour_23_rate', 6), ('voice_all_start_time_second_21_rate', 6), ('voice_all_end_time_hour_21_rate', 6), ('voice_all_start_time_second_0_rate', 6), ('voice_all_start_end_time_day_30_rate', 6), ('voice_all_end_time_second_11_rate', 6), ('voice_all_end_time_minute_11_rate', 6), ('voice_all_diff_time_skew', 6), ('voice_all_end_time_minute_5_rate', 6), ('voice_all_end_time_second_42_rate', 6), ('voice_all_end_time_hour_14_rate', 6), ('voice_all_end_time_minute_58_rate', 6), ('voice_all_end_time_last_start_time_last_diff_rate', 6), ('voice_all_end_time_second_10_rate', 6), ('voice_all_end_time_minute_15_rate', 6), ('voice_all_end_time_second_9_rate', 6), ('voice_all_start_end_time_day_17_rate', 6), ('voice_all_end_time_second_2_rate', 6), ('voice_all_end_time_second_13_rate', 6), ('voice_all_end_time_minute_52_rate', 6), ('voice_all_start_time_second_52_rate', 6), ('voice_all_end_time_second_25_rate', 6), ('voice_all_end_time_minute_14_rate', 6), ('voice_all_start_time_minute_24_rate', 6), ('voice_all_end_time_minute_55', 6), ('voice_all_opp_head_unique_cnt', 6), ('voice_all_start_time_minute_21_rate', 6), ('voice_all_start_time_second_33_rate', 6), ('voice_all_start_time_minute_7_rate', 6), ('voice_all_start_time_minute_40_rate', 6), ('voice_all_start_time_second_55_rate', 6), ('voice_all_opp_head_many_head_cnt', 6), ('voice_all_start_end_time_day_10', 5), ('voice_all_start_end_time_day_22_rate', 5), ('voice_all_start_time_hour_13_rate', 5), ('voice_all_start_time_second_35_rate', 5), ('voice_all_start_end_time_day_35_rate', 5), ('voice_all_end_time_minute_16_rate', 5), ('voice_all_end_time_second_40_rate', 5), ('voice_all_start_time_second_2_rate', 5), ('voice_all_start_time_minute_6_rate', 5), ('voice_all_end_time_hour_23', 5), ('voice_all_end_time_second_56_rate', 5), ('voice_all_end_time_second_50_rate', 5), ('voice_all_end_time_second_43_rate', 5), ('voice_all_start_time_second_3_rate', 5), ('voice_all_end_time_minute_25_rate', 5), ('voice_all_end_time_second_22_rate', 5), ('voice_all_diff_time_std', 5), ('voice_all_start_end_time_day_41_rate', 5), ('voice_all_start_time_second_48_rate', 5), ('voice_all_end_time_second_34_rate', 5), ('voice_all_start_time_second_11_rate', 5), ('voice_all_end_time_minute_7_rate', 5), ('voice_all_call_type_2', 5), ('voice_all_end_time_second_26_rate', 5), ('voice_all_start_time_minute_9_rate', 5), ('voice_all_start_time_hour_20_rate', 5), ('voice_all_end_time_second_28_rate', 5), ('voice_all_end_time_minute_3_rate', 5), ('voice_all_opp_len_9', 5), ('voice_all_start_end_time_day_33_rate', 5), ('voice_all_start_time_second_14_rate', 5), ('voice_all_end_time_hour_20_rate', 5), ('voice_all_start_time_second_44_rate', 5), ('voice_all_end_time_second_8_rate', 5), ('voice_all_start_time_second_31_rate', 5), ('voice_all_start_time_second_42_rate', 5), ('voice_all_start_time_minute_43_rate', 5), ('voice_all_end_time_second_6_rate', 5), ('voice_all_start_time_minute_35_rate', 5), ('voice_all_start_time_second_26_rate', 5), ('voice_all_end_time_minute_12_rate', 5), ('voice_all_start_time_hour_21', 5), ('voice_all_end_time_second_32_rate', 5), ('voice_all_start_end_time_day_14_rate', 5), ('voice_all_end_time_minute_17_rate', 5), ('voice_all_start_time_hour_5_rate', 5), ('voice_all_start_time_minute_13_rate', 4), ('voice_all_start_end_time_day_6', 4), ('voice_all_start_end_time_day_2', 4), ('voice_all_start_time_second_54_rate', 4), ('voice_all_end_time_minute_0_rate', 4), ('voice_all_start_time_second_59', 4), ('voice_all_start_time_second_24_rate', 4), ('voice_all_end_time_minute_51_rate', 4), ('voice_all_start_time_second_12_rate', 4), ('voice_all_start_time_minute_45_rate', 4), ('voice_all_end_time_minute_33_rate', 4), ('voice_all_start_time_minute_37_rate', 4), ('voice_all_start_end_time_day_7_rate', 4), ('voice_all_end_time_second_46_rate', 4), ('voice_all_start_time_second_7_rate', 4), ('voice_all_end_time_minute_53_rate', 4), ('voice_all_start_time_second_4_rate', 4), ('voice_all_start_end_time_day_9_rate', 4), ('voice_all_end_time_hour_12_rate', 4), ('voice_all_end_time_second_27_rate', 4), ('voice_all_start_end_time_day_36_rate', 4), ('voice_all_end_time_second_20_rate', 4), ('voice_all_end_time_second_29_rate', 4), ('voice_all_end_time_second_33_rate', 4), ('voice_all_start_time_minute_17_rate', 4), ('voice_all_start_time_second_5_rate', 4), ('voice_all_start_time_minute_0_rate', 4), ('voice_all_start_end_time_day_3_rate', 4), ('voice_all_end_time_minute_49_rate', 4), ('voice_all_start_time_second_30_rate', 4), ('voice_all_start_time_second_20_rate', 4), ('voice_all_end_time_hour_9_rate', 4), ('voice_all_start_time_minute_16_rate', 4), ('voice_all_end_time_minute_28_rate', 4), ('voice_all_in_out_0', 4), ('voice_all_start_end_time_day_43_rate', 4), ('voice_all_end_time_second_38_rate', 4), ('voice_all_end_time_minute_8_rate', 4), ('voice_all_start_time_second_40_rate', 4), ('voice_all_end_time_second_7_rate', 4), ('voice_all_end_time_hour_10_rate', 4), ('voice_all_end_time_minute_45_rate', 4), ('voice_all_start_time_minute_41_rate', 4), ('voice_all_start_time_second_17_rate', 4), ('voice_all_end_time_minute_38_rate', 4), ('voice_all_start_time_second_23_rate', 4), ('voice_all_start_end_time_day_10_rate', 4), ('voice_all_end_time_second_52_rate', 4), ('voice_all_end_time_minute_21_rate', 4), ('voice_all_start_time_minute_1_rate', 4), ('voice_all_start_end_time_day_11_rate', 4), ('voice_all_end_time_minute_8', 4), ('voice_all_end_time_second_5_rate', 4), ('voice_all_end_time_second_30_rate', 4), ('voice_all_end_time_std', 4), ('voice_all_end_time_minute_34_rate', 4), ('voice_all_end_time_second_21_rate', 4), ('voice_all_start_time_second_46_rate', 4), ('voice_all_start_time_second_29_rate', 4), ('voice_all_start_end_time_day_15_rate', 4), ('voice_all_start_time_second_41_rate', 4), ('voice_all_start_time_second_38_rate', 3), ('voice_all_start_end_time_day_6_rate', 3), ('voice_all_start_end_time_day_5', 3), ('voice_all_start_end_time_day_3', 3), ('voice_all_start_end_time_day_16', 3), ('voice_all_start_end_time_day_13', 3), ('voice_all_end_time_second_31_rate', 3), ('voice_all_start_end_time_day_5_rate', 3), ('voice_all_end_time_hour_18_rate', 3), ('voice_all_start_time_minute_44_rate', 3), ('voice_all_start_time_second_37_rate', 3), ('voice_all_start_time_second_15_rate', 3), ('voice_all_end_time_second_17_rate', 3), ('voice_all_end_time_minute_30_rate', 3), ('voice_all_end_time_minute_59_rate', 3), ('voice_all_end_time_minute_44_rate', 3), ('voice_all_end_time_minute_42_rate', 3), ('voice_all_end_time_second_53_rate', 3), ('voice_all_end_time_second_48_rate', 3), ('voice_all_start_time_minute_38_rate', 3), ('voice_all_start_end_time_day_25', 3), ('voice_all_start_time_minute_25_rate', 3), ('voice_all_start_end_time_day_4_rate', 3), ('voice_all_start_time_minute_1', 3), ('voice_all_start_end_time_day_31_rate', 3), ('voice_all_start_time_second_45_rate', 3), ('voice_all_start_time_second_39_rate', 3), ('voice_all_start_time_second_6_rate', 3), ('voice_all_end_time_minute_2_rate', 3), ('voice_all_start_end_time_day_41', 3), ('voice_all_end_time_second_47_rate', 3), ('voice_all_end_time_last', 3), ('voice_all_start_time_minute_4_rate', 3), ('voice_all_start_time_minute_46_rate', 3), ('voice_all_end_time_second_18_rate', 3), ('voice_all_start_time_minute_28_rate', 3), ('voice_all_end_time_second_37_rate', 3), ('voice_all_start_end_time_day_12_rate', 3), ('voice_all_end_time_minute_18_rate', 3), ('voice_all_end_time_minute_47_rate', 3), ('voice_all_start_end_time_day_39', 3), ('voice_all_start_end_time_day_36', 3), ('voice_all_start_time_minute_48_rate', 3), ('voice_all_start_time_minute_47_rate', 3), ('voice_all_start_end_time_day_1_rate', 3), ('voice_all_end_time_minute_4_rate', 3), ('voice_all_start_time_second_23', 3), ('voice_all_start_time_second_19_rate', 3), ('voice_all_start_time_second_43_rate', 3), ('voice_all_end_time_minute_57', 3), ('voice_all_start_end_time_day_18_rate', 3), ('voice_all_start_time_second_16_rate', 3), ('voice_all_start_time_minute_8_rate', 3), ('voice_all_end_time_second_15_rate', 3), ('voice_all_start_time_minute_52_rate', 3), ('voice_all_end_time_second_58_rate', 3), ('voice_all_end_time_second_4_rate', 3), ('voice_all_end_time_hour_15_rate', 3), ('voice_all_start_time_hour_20', 3), ('voice_all_end_time_minute_19_rate', 3), ('voice_all_end_time_minute_54_rate', 3), ('voice_all_start_time_minute_36_rate', 3), ('voice_all_start_time_minute_32_rate', 2), ('voice_all_end_time_second_9', 2), ('voice_all_start_end_time_day_7', 2), ('voice_all_start_time_second_59_rate', 2), ('voice_all_start_time_minute_46', 2), ('voice_all_start_end_time_day_19', 2), ('voice_all_end_time_hour_19_rate', 2), ('voice_all_start_time_minute_26_rate', 2), ('voice_all_end_time_minute_24_rate', 2), ('voice_all_end_time_minute_29_rate', 2), ('voice_all_start_time_minute_42_rate', 2), ('voice_all_end_time_second_41_rate', 2), ('voice_all_start_time_minute_27_rate', 2), ('voice_all_start_time_minute_23_rate', 2), ('voice_all_start_time_second_25_rate', 2), ('voice_all_start_time_minute_39_rate', 2), ('voice_all_end_time_second_11', 2), ('voice_all_end_time_minute_36_rate', 2), ('voice_all_end_time_second_45_rate', 2), ('voice_all_start_time_hour_16', 2), ('voice_all_start_time_hour_14', 2), ('voice_all_start_time_hour_15', 2), ('voice_all_start_time_hour_0', 2), ('voice_all_start_end_time_day_23_rate', 2), ('voice_all_end_time_second_14_rate', 2), ('voice_all_start_time_minute_15_rate', 2), ('voice_all_start_end_time_day_21', 2), ('voice_all_start_time_second_24', 2), ('voice_all_start_time_hour_18_rate', 2), ('voice_all_start_time_second_50_rate', 2), ('voice_all_end_time_minute_42', 2), ('voice_all_diff_time_jc', 2), ('voice_all_end_time_hour_5_rate', 2), ('voice_all_start_time_second_57_rate', 2), ('voice_all_start_time_min', 2), ('voice_all_start_end_time_day_13_rate', 2), ('voice_all_start_time_second_49_rate', 2), ('voice_all_start_time_second_9', 2), ('voice_all_start_time_second_5', 2), ('voice_all_start_time_second_39', 2), ('voice_all_end_time_hour_1_rate', 2), ('voice_all_start_time_second_31', 2), ('voice_all_start_time_second_32', 2), ('voice_all_end_time_hour_6_rate', 2), ('voice_all_end_time_minute_35_rate', 2), ('voice_all_start_time_second_47_rate', 2), ('voice_all_end_time_minute_41', 2), ('voice_all_end_time_minute_49', 2), ('voice_all_in_out_1', 2), ('voice_all_end_time_second_36', 2), ('voice_all_start_time_minute_33_rate', 2), ('voice_all_start_time_second_10_rate', 2), ('voice_all_end_time_sum', 2), ('voice_all_end_time_min', 2), ('voice_all_end_time_second_0', 2), ('voice_all_start_time_minute_34_rate', 2), ('voice_all_start_time_hour_8', 2), ('voice_all_start_time_minute_22', 2), ('voice_all_start_time_minute_29', 2), ('voice_all_start_end_time_day_27_rate', 2), ('voice_all_start_end_time_day_44_rate', 2), ('voice_all_start_time_minute_57', 2), ('voice_all_start_time_minute_3_rate', 2), ('voice_all_start_time_second_36_rate', 2), ('voice_all_end_time_minute_24', 2), ('voice_all_start_end_time_day_38_rate', 2), ('voice_all_end_time_second_45', 2), ('voice_all_end_time_minute_9', 2), ('voice_all_end_time_fd', 2), ('voice_all_end_time_second_44_rate', 2), ('voice_all_start_end_time_day_20', 2), ('voice_all_start_time_minute_16', 2), ('voice_all_end_time_second_3_rate', 2), ('voice_all_end_time_second_36_rate', 2), ('voice_all_start_time_second_17', 2), ('voice_all_end_time_hour_15', 2), ('voice_all_end_time_hour_14', 2), ('voice_all_start_time_hour_0_rate', 2), ('voice_all_end_time_minute_32_rate', 2), ('voice_all_start_end_time_day_45_rate', 2), ('voice_all_start_time_second_8_rate', 2), ('voice_all_start_end_time_day_17', 2), ('voice_all_end_time_minute_50_rate', 2), ('voice_all_end_time_minute_37_rate', 2), ('voice_all_end_time_second_16_rate', 2), ('voice_all_end_time_minute_27_rate', 2), ('voice_all_end_time_second_44', 1), ('voice_all_start_time_second_52', 1), ('voice_all_start_end_time_day_1', 1), ('voice_all_start_time_minute_45', 1), ('voice_all_start_time_minute_40', 1), ('voice_all_start_end_time_day_15', 1), ('voice_all_start_end_time_day_12', 1), ('voice_all_start_time_hour_1_rate', 1), ('voice_all_end_time_second_55', 1), ('voice_all_end_time_second_57', 1), ('voice_all_end_time_second_51', 1), ('voice_all_start_time_minute_20_rate', 1), ('voice_all_start_time_second_56_rate', 1), ('voice_all_end_time_minute_39', 1), ('voice_all_end_time_skew', 1), ('voice_all_start_end_time_day_8', 1), ('voice_all_start_end_time_day_4', 1), ('voice_all_start_time_minute_2_rate', 1), ('voice_all_end_time_second_18', 1), ('voice_all_end_time_hour_20', 1), ('voice_all_end_time_hour_21', 1), ('voice_all_start_time_hour_18', 1), ('voice_all_end_time_avg', 1), ('voice_all_start_time_hour_12', 1), ('voice_all_start_time_hour_11', 1), ('voice_all_end_time_minute_31_rate', 1), ('voice_all_start_time_hour_4', 1), ('voice_all_start_time_hour_19', 1), ('voice_all_end_time_second_12_rate', 1), ('voice_all_start_time_hour_13', 1), ('voice_all_start_end_time_day_29_rate', 1), ('voice_all_start_time_minute_12', 1), ('voice_all_start_time_minute_0', 1), ('voice_all_end_time_second_28', 1), ('voice_all_end_time_second_21', 1), ('voice_all_end_time_second_22', 1), ('voice_all_end_time_second_27', 1), ('voice_all_end_time_hour_23_rate', 1), ('voice_all_end_time_second_52', 1), ('voice_all_start_end_time_day_42', 1), ('voice_all_start_end_time_day_43', 1), ('voice_all_start_end_time_day_45', 1), ('voice_all_start_time_minute_34', 1), ('voice_all_start_time_minute_30', 1), ('voice_all_start_time_minute_38', 1), ('voice_all_start_time_second_1', 1), ('voice_all_start_time_second_2', 1), ('voice_all_start_time_second_33', 1), ('voice_all_start_time_second_36', 1), ('voice_all_call_type_1', 1), ('voice_all_opp_len_many_head', 1), ('voice_all_end_time_minute_43', 1), ('voice_all_start_time_minute_50_rate', 1), ('voice_all_end_time_minute_26_rate', 1), ('voice_all_end_time_last_end_time_first_diff', 1), ('voice_all_end_time_minute_36', 1), ('voice_all_start_time_minute_49', 1), ('voice_all_start_end_time_day_40', 1), ('voice_all_end_time_second_32', 1), ('voice_all_diff_time_sum', 1), ('voice_all_end_time_second_5', 1), ('voice_all_end_time_second_8', 1), ('voice_all_end_time_minute_56_rate', 1), ('voice_all_end_time_minute_19', 1), ('voice_all_end_time_minute_16', 1), ('voice_all_end_time_minute_11', 1), ('voice_all_end_time_minute_10', 1), ('voice_all_start_time_hour_6', 1), ('voice_all_end_time_minute_22_rate', 1), ('voice_all_start_time_minute_26', 1), ('voice_all_start_time_minute_25', 1), ('voice_all_start_time_minute_24', 1), ('voice_all_start_time_minute_28', 1), ('voice_all_cnt', 1), ('voice_all_start_time_second_22', 1), ('voice_all_start_time_second_21', 1), ('voice_all_start_time_second_20', 1), ('voice_all_start_time_second_29', 1), ('voice_all_start_time_second_28', 1), ('voice_all_start_time_minute_54', 1), ('voice_all_start_time_minute_50', 1), ('voice_all_start_time_minute_51', 1), ('voice_all_end_time_jc', 1), ('voice_all_start_time_minute_14_rate', 1), ('voice_all_end_time_second_55_rate', 1), ('voice_all_start_time_minute_22_rate', 1), ('voice_all_end_time_second_43', 1), ('voice_all_end_time_second_40', 1), ('voice_all_end_time_hour_6', 1), ('voice_all_end_time_second_49', 1), ('voice_all_end_time_minute_23', 1), ('voice_all_start_time_second_34_rate', 1), ('voice_all_start_time_minute_30_rate', 1), ('voice_all_end_time_minute_10_rate', 1), ('voice_all_start_time_minute_54_rate', 1), ('voice_all_end_time_minute_4', 1), ('voice_all_start_end_time_day_26', 1), ('voice_all_start_end_time_day_22', 1), ('voice_all_start_time_second_18', 1), ('voice_all_start_time_second_19', 1), ('voice_all_start_time_second_16', 1), ('voice_all_start_time_second_10', 1), ('voice_all_start_time_second_11', 1), ('voice_all_opp_len_11', 1), ('voice_all_end_time_hour_17', 1), ('voice_all_start_time_hour_23', 1), ('voice_all_start_time_hour_22', 1), ('voice_all_start_end_time_day_28_rate', 1), ('voice_all_start_time_minute_57_rate', 1), ('voice_all_end_time_minute_52', 1), ('voice_all_end_time_second_7', 1), ('voice_all_end_time_second_1', 1)]\n"
     ]
    }
   ],
   "source": [
    "# 计算特征重要程度\n",
    "import operator\n",
    "importance = model.get_fscore()\n",
    "importance = sorted(importance.items(), key=operator.itemgetter(1),reverse=True)\n",
    "\n",
    "print importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 复制lable的数据，作为所有的特征的标示\n",
    "df_train = df_train_label.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1150778 entries, 0 to 1150777\n",
      "Data columns (total 8 columns):\n",
      "uid           1150778 non-null object\n",
      "opp_num       1150778 non-null object\n",
      "opp_head      1150778 non-null object\n",
      "opp_len       1150778 non-null int64\n",
      "start_time    1150778 non-null int64\n",
      "end_time      1150778 non-null int64\n",
      "call_type     1150778 non-null int64\n",
      "in_out        1150778 non-null int64\n",
      "dtypes: int64(5), object(3)\n",
      "memory usage: 70.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_voice.head()\n",
    "df_train_voice.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df_train_voice.groupby('uid',as_index=True)['opp_num'].unique()\n",
    "uids = tmp.index\n",
    "opp_nums = []\n",
    "for opp_num in tmp:\n",
    "    opp_nums.append(len(opp_num))\n",
    "\n",
    "df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_num_unique_cnt':opp_nums})\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_num'].count())\n",
    "df_tmp.columns = ['voice_all_opp_num_cnt']\n",
    "df_tmp['uid'] = df_tmp.index\n",
    "\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通话次数 / 通话的人数\n",
    "df_train['voice_opp_num_all_cnt_unique_cnt_rate'] = df_train['voice_all_opp_num_cnt'] / df_train['voice_all_opp_num_unique_cnt']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "uid\n",
       "u0001      79\n",
       "u0002       2\n",
       "u0003      21\n",
       "u0004     254\n",
       "u0005     401\n",
       "u0006      44\n",
       "u0007     101\n",
       "u0008     234\n",
       "u0009      96\n",
       "u0010     130\n",
       "u0011     227\n",
       "u0012     302\n",
       "u0013       2\n",
       "u0014     151\n",
       "u0015      81\n",
       "u0016     291\n",
       "u0017      43\n",
       "u0018     178\n",
       "u0019     647\n",
       "u0020     315\n",
       "u0021      19\n",
       "u0022      22\n",
       "u0023      32\n",
       "u0024     653\n",
       "u0025     723\n",
       "u0026     521\n",
       "u0027    1618\n",
       "u0028     323\n",
       "u0029      13\n",
       "u0030      62\n",
       "         ... \n",
       "u4970     415\n",
       "u4971     277\n",
       "u4972     468\n",
       "u4973     485\n",
       "u4974     180\n",
       "u4975     288\n",
       "u4976     262\n",
       "u4977      76\n",
       "u4978      97\n",
       "u4979       8\n",
       "u4980       3\n",
       "u4981       3\n",
       "u4982      35\n",
       "u4983      30\n",
       "u4984       4\n",
       "u4985       3\n",
       "u4986       1\n",
       "u4987       5\n",
       "u4988       1\n",
       "u4989      93\n",
       "u4990     324\n",
       "u4991      60\n",
       "u4992     263\n",
       "u4993      11\n",
       "u4994      25\n",
       "u4995      18\n",
       "u4996      30\n",
       "u4997      54\n",
       "u4998      18\n",
       "u4999      19\n",
       "Name: opp_head, Length: 4987, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 全部的不同开头的次数,唯一的标示\n",
    "tmp = df_train_voice.groupby('uid',as_index=True)['opp_head'].unique()\n",
    "uids = tmp.index\n",
    "opp_nums = []\n",
    "for opp_num in tmp:\n",
    "    opp_nums.append(len(opp_num))\n",
    "\n",
    "df_tmp = pd.DataFrame(data={'uid':uids, 'voice_all_opp_head_unique_cnt':opp_nums})\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "    \n",
    "# 通话次数 / opp_len的次数\n",
    "df_train['voice_opp_head_all_cnt_unique_cnt_rate'] = df_train['voice_all_opp_num_cnt'] / df_train['voice_all_opp_head_unique_cnt']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通话最多的head的个数，\n",
    "df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_head'].value_counts().unstack().max(axis=1))\n",
    "df_tmp.columns = ['voice_all_opp_head_max']\n",
    "df_tmp['uid'] = df_tmp.index\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "\n",
    "# 通话最小的head的个数，\n",
    "df_tmp = pd.DataFrame(df_train_voice.groupby('uid',as_index=True)['opp_head'].value_counts().unstack().min(axis=1))\n",
    "df_tmp.columns = ['voice_all_opp_head_min']\n",
    "df_tmp['uid'] = df_tmp.index\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n",
    "\n",
    "# 极差，和占总个比例\n",
    "df_train['voice_all_opp_head_jc'] = df_train['voice_all_opp_head_max'] - df_train['voice_all_opp_head_min']\n",
    "df_train['voice_opp_head_all_max_rate'] = df_train['voice_all_opp_head_max'] / df_train['voice_all_opp_num_cnt']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1014721\n",
       "3      78307\n",
       "2      57595\n",
       "5        125\n",
       "4         30\n",
       "Name: call_type, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_voice['call_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_type 分布\n",
    "df_tmp = df_train_voice.groupby('uid',as_index=True)['call_type'].value_counts().unstack()\n",
    "df_tmp.columns = ['voice_all_call_type_'+str(i) for i in range(1,6)]\n",
    "df_tmp['uid'] = df_tmp.index\n",
    "df_tmp.fillna(0,inplace=True)\n",
    "\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call_type 分布\n",
    "df_tmp = df_train_voice.groupby('uid',as_index=True)['in_out'].value_counts().unstack()\n",
    "\n",
    "df_tmp.columns = ['voice_all_in_out_'+str(i) for i in range(2)]\n",
    "df_tmp['uid'] = df_tmp.index\n",
    "df_tmp.fillna(0,inplace=True)\n",
    "\n",
    "df_train = pd.merge(df_train, df_tmp, on='uid', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
