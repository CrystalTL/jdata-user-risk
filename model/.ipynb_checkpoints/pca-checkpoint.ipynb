{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def diff_time(a,b):\n",
    "    a_day, a_hour, a_minute, a_second = (a / 1000000, a / 10000 % 100, a / 100 % 100, a % 100)\n",
    "    b_day, b_hour, b_minute, b_second = (b / 1000000, b / 10000 % 100, b / 100 % 100, b % 100)\n",
    "    \n",
    "    d_day = b_day - a_day\n",
    "    d_hour = b_hour - a_hour\n",
    "    d_minute = b_minute - a_minute\n",
    "    d_second = b_second - a_second\n",
    "    \n",
    "    diff = d_day * 24 * 60 * 60 + d_hour * 60 * 60 + d_minute * 60 + d_second\n",
    "    return diff\n",
    "\n",
    "def get_diff_time(x):\n",
    "    diff_t = []\n",
    "    for d in x:\n",
    "#         print d\n",
    "        diff_t.append(diff_time(d[0],d[1]))\n",
    "    return diff_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data(add_data=False):\n",
    "    df_train_voice_feat = pd.read_csv('../xdata/df_train_voice_feat.csv')\n",
    "    df_test_voice_feat = pd.read_csv('../xdata/df_testB_voice_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA = pd.read_csv('../xdata/df_testA_label.csv')\n",
    "        df_trainA_voice_feat = pd.read_csv('../xdata/df_testA_voice_feat.csv')\n",
    "        \n",
    "    \n",
    "    df_train_sms_feat = pd.read_csv('../xdata/df_train_sms_feat.csv')\n",
    "    df_test_sms_feat = pd.read_csv('../xdata/df_testB_sms_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA_sms_feat = pd.read_csv('../xdata/df_testA_sms_feat.csv')\n",
    "    \n",
    "    df_train_sms_feat.drop('label',axis=1,inplace=True)\n",
    "    \n",
    "    df_train_wa_feat = pd.read_csv('../xdata/df_train_wa_feat.csv')\n",
    "    df_test_wa_feat = pd.read_csv('../xdata/df_testB_wa_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA_wa_feat = pd.read_csv('../xdata/df_testA_wa_feat.csv')\n",
    "    df_train_wa_feat.drop('label',axis=1,inplace=True)\n",
    "    \n",
    "#     df_train_voice_sms_feat = pd.read_csv('../xdata/df_train_voice_sms_feat.csv')\n",
    "#     df_test_voice_sms_feat = pd.read_csv('../xdata/df_testB_voice_sms_feat.csv')\n",
    "#     df_train_voice_sms_feat.drop('label',axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    df_train = pd.merge(df_train_voice_feat, df_train_sms_feat, on='uid', how='left')\n",
    "    df_test = pd.merge(df_test_voice_feat, df_test_sms_feat, on='uid', how='left')\n",
    "    \n",
    "    df_train = pd.merge(df_train, df_train_wa_feat, on='uid', how='left')\n",
    "    df_test = pd.merge(df_test, df_test_wa_feat, on='uid', how='left')\n",
    "    \n",
    "#     df_train = pd.merge(df_train, df_train_voice_sms_feat, on='uid', how='left')\n",
    "#     df_test = pd.merge(df_test, df_test_voice_sms_feat, on='uid', how='left')\n",
    "    \n",
    "    \n",
    "    if add_data==True:\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_voice_feat, on='uid', how='left')\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_sms_feat, on='uid', how='left')\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_wa_feat, on='uid', how='left')\n",
    "#         df_trainA = df_trainA[df_trainA['label']==1]\n",
    "        df_trainA = df_trainA[:100]\n",
    "        \n",
    "        \n",
    "        df_train = df_train.append(df_trainA)\n",
    "    \n",
    "        \n",
    "    df_train.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_test.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "\n",
    "    df_train.fillna(0,inplace=True)\n",
    "    df_test.fillna(0,inplace=True)\n",
    "\n",
    "    \n",
    "    \n",
    "    # 组合特征\n",
    "    # voice_all_start_time_first\n",
    "    # voice_all_start_time_last \n",
    "    # voice_all_end_time_first\n",
    "    # voice_all_end_time_last\n",
    "    \n",
    "    # sms_all_start_time_last\n",
    "    # sms_all_start_time_first\n",
    "    for sms_time in ['sms_all_start_time_first', 'sms_all_start_time_last']:\n",
    "        df_train[sms_time] = df_train[sms_time].astype(int)\n",
    "        df_test[sms_time] = df_test[sms_time].astype(int)\n",
    "        \n",
    "        for voice_time in ['voice_all_start_time_first','voice_all_start_time_last','voice_all_end_time_first','voice_all_end_time_last']:\n",
    "            df_train[voice_time] = df_train[voice_time].astype(int)\n",
    "            df_test[voice_time] = df_test[voice_time].astype(int)\n",
    "        \n",
    "            df_train[sms_time+'_'+voice_time] = get_diff_time(df_train[[sms_time,voice_time]].values)\n",
    "            df_test[sms_time+'_'+voice_time] = get_diff_time(df_test[[sms_time,voice_time]].values)\n",
    "            \n",
    "            # 除以对应的不同的次数，\n",
    "            df_train[sms_time+'_'+voice_time+'_voice_rate'] = df_train[sms_time+'_'+voice_time] / df_train['voice_all_cnt']\n",
    "            df_test[sms_time+'_'+voice_time+'_voice_rate'] = df_test[sms_time+'_'+voice_time] / df_test['voice_all_cnt']\n",
    "    \n",
    "            df_train[sms_time+'_'+voice_time+'_sms_rate'] = df_train[sms_time+'_'+voice_time] / df_train['sms_all_cnt']\n",
    "            df_test[sms_time+'_'+voice_time+'_sms_rate'] = df_test[sms_time+'_'+voice_time] / df_test['sms_all_cnt']\n",
    "    \n",
    "    df_train['wa_all_wa_name_little_wite_risk'] = df_train['wa_all_wa_name_little_wite_risk'].astype(int)\n",
    "    df_train['wa_all_wa_name_many_wite_risk'] = df_train['wa_all_wa_name_many_wite_risk'].astype(int)\n",
    "    \n",
    "    df_test['wa_all_wa_name_little_wite_risk'] = df_test['wa_all_wa_name_little_wite_risk'].astype(int)\n",
    "    df_test['wa_all_wa_name_many_wite_risk'] = df_test['wa_all_wa_name_many_wite_risk'].astype(int)\n",
    "\n",
    "    df_train.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_test.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "\n",
    "    df_train.fillna(0,inplace=True)\n",
    "    df_test.fillna(0,inplace=True)\n",
    "\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "    \n",
    "    \n",
    "def split_train_valid(df_train,test_size=0.2):\n",
    "    '''\n",
    "    k-fold交叉验证,默认k=10\n",
    "    df_train:训练数据\n",
    "    '''\n",
    "    X_train, X_vali, y_train, y_vali = train_test_split(df_train[features], df_train[label], test_size=test_size, random_state=40000)\n",
    "    #added some parameters\n",
    "    \n",
    "#     dtrain = df_train.iloc[train_list]\n",
    "#     dvali =  df_train.iloc[vali_list]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_vali,label=y_vali)\n",
    "    watchlist = [(dtrain, 'train'),(dvalid, 'valid')]\n",
    "    \n",
    "    return dtrain, dvalid, watchlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5099 entries, 0 to 99\n",
      "Columns: 2065 entries, label to sms_all_start_time_last_voice_all_end_time_last_sms_rate\n",
      "dtypes: float64(2043), int64(19), object(3)\n",
      "memory usage: 80.4+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 0 to 2999\n",
      "Columns: 2064 entries, uid to sms_all_start_time_last_voice_all_end_time_last_sms_rate\n",
      "dtypes: float64(2043), int64(18), object(3)\n",
      "memory usage: 47.3+ MB\n",
      "2061\n",
      "1155\n"
     ]
    }
   ],
   "source": [
    "# 设置特征数据，去除id数据，不能进行预测\n",
    "df_train, df_test = get_data(add_data=True)\n",
    "\n",
    "df_train.info()\n",
    "df_test.info()\n",
    "\n",
    "features = df_test.columns\n",
    "features = list(features)\n",
    "features.remove('uid')\n",
    "features.remove('wa_all_wa_name_little_wite')\n",
    "features.remove('wa_all_wa_name_many_wite')\n",
    "\n",
    "label = 'label'\n",
    "\n",
    "print len(features)\n",
    "\n",
    "features_ = open('no_xfeatures906.txt','r').readlines()\n",
    "features_ = [feat.strip() for feat in features_]\n",
    "\n",
    "print len(features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "train_pac = pca.fit_transform(df_train[features_])\n",
    "\n",
    "test_pac = pca.fit_transform(df_test[features_])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(train_pac.shape[1]):\n",
    "    df_train['PCA_'  str(i)] =  train_pac[:,1]\n",
    "    df_test['PCA_' + str(i)] = test_pac[:,1]\n",
    "    pac_feat.append('')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = open('xfeatures906.txt','r').readlines()\n",
    "features = [feat.strip() for feat in features_]\n",
    "\n",
    "features = features + ['PCA_%d' % i for i in range(train_pac.shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)\n",
    "seed = 71\n",
    "np.random.seed(seed)\n",
    "param = {'max_depth':3, # 基准是5,过拟合 \n",
    "         'eta':0.05,\n",
    "         'gamma ':0.1,\n",
    "         'colsample_bytree':0.8, # old 0.8\n",
    "         'subsample':0.8,\n",
    "         'silent':1,\n",
    "         'eval_metric':'auc',\n",
    "         'objective':'binary:logistic',\n",
    "#          'scale_pos_weight':5,\n",
    "         'seed': seed\n",
    "        }\n",
    "\n",
    "ESR = 50\n",
    "nround = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('LOOP', 0)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['PCA_0' 'PCA_1' 'PCA_2' 'PCA_3' 'PCA_4' 'PCA_5' 'PCA_6' 'PCA_7' 'PCA_8'\\n 'PCA_9' 'PCA_10' 'PCA_11' 'PCA_12' 'PCA_13' 'PCA_14' 'PCA_15' 'PCA_16'\\n 'PCA_17' 'PCA_18' 'PCA_19' 'PCA_20' 'PCA_21' 'PCA_22' 'PCA_23' 'PCA_24'\\n 'PCA_25' 'PCA_26' 'PCA_27' 'PCA_28' 'PCA_29' 'PCA_30' 'PCA_31' 'PCA_32'\\n 'PCA_33' 'PCA_34' 'PCA_35' 'PCA_36' 'PCA_37' 'PCA_38' 'PCA_39' 'PCA_40'\\n 'PCA_41' 'PCA_42' 'PCA_43' 'PCA_44' 'PCA_45' 'PCA_46' 'PCA_47' 'PCA_48'\\n 'PCA_49' 'PCA_50' 'PCA_51' 'PCA_52' 'PCA_53' 'PCA_54' 'PCA_55' 'PCA_56'\\n 'PCA_57' 'PCA_58' 'PCA_59' 'PCA_60' 'PCA_61' 'PCA_62' 'PCA_63' 'PCA_64'\\n 'PCA_65' 'PCA_66' 'PCA_67' 'PCA_68' 'PCA_69' 'PCA_70' 'PCA_71' 'PCA_72'\\n 'PCA_73' 'PCA_74' 'PCA_75' 'PCA_76' 'PCA_77' 'PCA_78' 'PCA_79' 'PCA_80'\\n 'PCA_81' 'PCA_82' 'PCA_83' 'PCA_84' 'PCA_85' 'PCA_86' 'PCA_87' 'PCA_88'\\n 'PCA_89' 'PCA_90' 'PCA_91' 'PCA_92' 'PCA_93' 'PCA_94' 'PCA_95' 'PCA_96'\\n 'PCA_97' 'PCA_98' 'PCA_99' 'PCA_100' 'PCA_101' 'PCA_102' 'PCA_103'\\n 'PCA_104' 'PCA_105' 'PCA_106' 'PCA_107' 'PCA_108' 'PCA_109' 'PCA_110'\\n 'PCA_111' 'PCA_112' 'PCA_113' 'PCA_114' 'PCA_115' 'PCA_116' 'PCA_117'\\n 'PCA_118' 'PCA_119' 'PCA_120' 'PCA_121' 'PCA_122' 'PCA_123' 'PCA_124'\\n 'PCA_125' 'PCA_126' 'PCA_127' 'PCA_128' 'PCA_129' 'PCA_130' 'PCA_131'\\n 'PCA_132' 'PCA_133' 'PCA_134' 'PCA_135' 'PCA_136' 'PCA_137' 'PCA_138'\\n 'PCA_139' 'PCA_140' 'PCA_141' 'PCA_142' 'PCA_143' 'PCA_144' 'PCA_145'\\n 'PCA_146' 'PCA_147' 'PCA_148' 'PCA_149' 'PCA_150' 'PCA_151' 'PCA_152'\\n 'PCA_153' 'PCA_154' 'PCA_155' 'PCA_156' 'PCA_157' 'PCA_158' 'PCA_159'\\n 'PCA_160' 'PCA_161' 'PCA_162' 'PCA_163' 'PCA_164' 'PCA_165' 'PCA_166'\\n 'PCA_167' 'PCA_168' 'PCA_169' 'PCA_170' 'PCA_171' 'PCA_172' 'PCA_173'\\n 'PCA_174' 'PCA_175' 'PCA_176' 'PCA_177' 'PCA_178' 'PCA_179' 'PCA_180'\\n 'PCA_181' 'PCA_182' 'PCA_183' 'PCA_184' 'PCA_185' 'PCA_186' 'PCA_187'\\n 'PCA_188' 'PCA_189' 'PCA_190' 'PCA_191' 'PCA_192' 'PCA_193' 'PCA_194'\\n 'PCA_195' 'PCA_196' 'PCA_197' 'PCA_198' 'PCA_199'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8dac5076719d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LOOP'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#     dbuild, dvalid, watchlist = split_build_valid(df_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnround\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mESR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-67bfb9fe6eff>\u001b[0m in \u001b[0;36msplit_train_valid\u001b[0;34m(df_train, test_size)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mdf_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m训\u001b[0m\u001b[0;31m练\u001b[0m\u001b[0;31m数\u001b[0m\u001b[0;31m据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     '''\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vali\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_vali\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;31m#added some parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaoran/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1956\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1958\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1959\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaoran/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2000\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2001\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2002\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2003\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaoran/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1231\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['PCA_0' 'PCA_1' 'PCA_2' 'PCA_3' 'PCA_4' 'PCA_5' 'PCA_6' 'PCA_7' 'PCA_8'\\n 'PCA_9' 'PCA_10' 'PCA_11' 'PCA_12' 'PCA_13' 'PCA_14' 'PCA_15' 'PCA_16'\\n 'PCA_17' 'PCA_18' 'PCA_19' 'PCA_20' 'PCA_21' 'PCA_22' 'PCA_23' 'PCA_24'\\n 'PCA_25' 'PCA_26' 'PCA_27' 'PCA_28' 'PCA_29' 'PCA_30' 'PCA_31' 'PCA_32'\\n 'PCA_33' 'PCA_34' 'PCA_35' 'PCA_36' 'PCA_37' 'PCA_38' 'PCA_39' 'PCA_40'\\n 'PCA_41' 'PCA_42' 'PCA_43' 'PCA_44' 'PCA_45' 'PCA_46' 'PCA_47' 'PCA_48'\\n 'PCA_49' 'PCA_50' 'PCA_51' 'PCA_52' 'PCA_53' 'PCA_54' 'PCA_55' 'PCA_56'\\n 'PCA_57' 'PCA_58' 'PCA_59' 'PCA_60' 'PCA_61' 'PCA_62' 'PCA_63' 'PCA_64'\\n 'PCA_65' 'PCA_66' 'PCA_67' 'PCA_68' 'PCA_69' 'PCA_70' 'PCA_71' 'PCA_72'\\n 'PCA_73' 'PCA_74' 'PCA_75' 'PCA_76' 'PCA_77' 'PCA_78' 'PCA_79' 'PCA_80'\\n 'PCA_81' 'PCA_82' 'PCA_83' 'PCA_84' 'PCA_85' 'PCA_86' 'PCA_87' 'PCA_88'\\n 'PCA_89' 'PCA_90' 'PCA_91' 'PCA_92' 'PCA_93' 'PCA_94' 'PCA_95' 'PCA_96'\\n 'PCA_97' 'PCA_98' 'PCA_99' 'PCA_100' 'PCA_101' 'PCA_102' 'PCA_103'\\n 'PCA_104' 'PCA_105' 'PCA_106' 'PCA_107' 'PCA_108' 'PCA_109' 'PCA_110'\\n 'PCA_111' 'PCA_112' 'PCA_113' 'PCA_114' 'PCA_115' 'PCA_116' 'PCA_117'\\n 'PCA_118' 'PCA_119' 'PCA_120' 'PCA_121' 'PCA_122' 'PCA_123' 'PCA_124'\\n 'PCA_125' 'PCA_126' 'PCA_127' 'PCA_128' 'PCA_129' 'PCA_130' 'PCA_131'\\n 'PCA_132' 'PCA_133' 'PCA_134' 'PCA_135' 'PCA_136' 'PCA_137' 'PCA_138'\\n 'PCA_139' 'PCA_140' 'PCA_141' 'PCA_142' 'PCA_143' 'PCA_144' 'PCA_145'\\n 'PCA_146' 'PCA_147' 'PCA_148' 'PCA_149' 'PCA_150' 'PCA_151' 'PCA_152'\\n 'PCA_153' 'PCA_154' 'PCA_155' 'PCA_156' 'PCA_157' 'PCA_158' 'PCA_159'\\n 'PCA_160' 'PCA_161' 'PCA_162' 'PCA_163' 'PCA_164' 'PCA_165' 'PCA_166'\\n 'PCA_167' 'PCA_168' 'PCA_169' 'PCA_170' 'PCA_171' 'PCA_172' 'PCA_173'\\n 'PCA_174' 'PCA_175' 'PCA_176' 'PCA_177' 'PCA_178' 'PCA_179' 'PCA_180'\\n 'PCA_181' 'PCA_182' 'PCA_183' 'PCA_184' 'PCA_185' 'PCA_186' 'PCA_187'\\n 'PCA_188' 'PCA_189' 'PCA_190' 'PCA_191' 'PCA_192' 'PCA_193' 'PCA_194'\\n 'PCA_195' 'PCA_196' 'PCA_197' 'PCA_198' 'PCA_199'] not in index\""
     ]
    }
   ],
   "source": [
    "LOOP = 3\n",
    "models = []\n",
    "seeds = [71,73,91]\n",
    "for i in range(LOOP):\n",
    "    print('LOOP',i)\n",
    "#     dbuild, dvalid, watchlist = split_build_valid(df_train)\n",
    "    dbuild, dvalid, watchlist = split_train_valid(df_train,test_size=0.2)\n",
    "    param['seed'] = seeds[i]\n",
    "    model = xgb.train(param, dbuild, nround, watchlist,early_stopping_rounds=ESR,verbose_eval=20)\n",
    "    models.append(model)\n",
    "#     model.save_model('./model1'+ str(i) + '.model')\n",
    "    # VALID\n",
    "    valid_yhat = model.predict(dvalid,ntree_limit=model.best_iteration)\n",
    "    print('Valid Mean:---------------------->', np.mean(valid_yhat))\n",
    "    del dbuild, dvalid, watchlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
