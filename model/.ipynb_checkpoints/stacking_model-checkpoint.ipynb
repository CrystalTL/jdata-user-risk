{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "\n",
    "from sklearn.utils import shuffle  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ensemble model\n",
    "### model\n",
    "1. RF x 7\n",
    "2. GBDT x 11\n",
    "3. XGB x 17\n",
    "\n",
    "### feature\n",
    "1. all features\n",
    "2. used features\n",
    "3. no features\n",
    "\n",
    "### data\n",
    "1. 3 + 2\n",
    "2. second layer --> LR x 1 or [XGB x 3 (AVG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 得到模型的只，\n",
    "def get_x_rf(df_train, feats, label):\n",
    "    '''\n",
    "    使用9种不同的参数的models\n",
    "    '''\n",
    "    seed = 17\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    x_n_estimators = [20,100,500]\n",
    "    max_depth = 5\n",
    "    min_samples_split = 3\n",
    "    verbose = 10\n",
    "    x_random_states = [71, 91, 101]\n",
    "    \n",
    "    rf_models = []\n",
    "    data_res = {}\n",
    "    for i in range(len(x_n_estimators)):\n",
    "        for j in range(len(x_random_states)):\n",
    "            print i,j\n",
    "            clf = RandomForestClassifier(max_depth=max_depth, random_state=x_random_states[j],\n",
    "                                         min_samples_split=min_samples_split, \n",
    "                                         n_estimators=x_n_estimators[i],verbose=10)    \n",
    "            clf.fit(df_train[feats],df_train[label])\n",
    "            rf_model.append(clf)\n",
    "#             prob = clf.predict_proba(df_test[feats])\n",
    "#             data_rea['RF_%d_%d_PROB' % (i,j)] = prob\n",
    "    \n",
    "    return rf_models\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_valid(df_train,features,label,test_size=0.2):\n",
    "    '''\n",
    "    k-fold交叉验证,默认k=10\n",
    "    df_train:训练数据\n",
    "    '''\n",
    "    X_train, X_vali, y_train, y_vali = train_test_split(df_train[features], df_train[label], test_size=test_size, random_state=40000)\n",
    "    #added some parameters\n",
    "        \n",
    "    dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_vali,label=y_vali)\n",
    "    watchlist = [(dtrain, 'train'),(dvalid, 'valid')]\n",
    "    \n",
    "    return dtrain, dvalid, watchlist\n",
    "\n",
    "# 得到模型的只，\n",
    "def get_x_gbdt(df_train, feats, label):\n",
    "    '''\n",
    "    使用7种不同的参数\n",
    "    '''\n",
    "    seed = 17\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    learning_rate = 0.05\n",
    "    n_estimators = 180\n",
    "    max_depth = 3\n",
    "    min_samples_split = 2\n",
    "    subsample = 0.85\n",
    "    verbose = 50\n",
    "    x_random_states = [71,91,101,2018,2019,1007,2020]\n",
    "    \n",
    "    gbdt_models = []\n",
    "    data_res = {}\n",
    "    for j in range(len(x_random_states)):\n",
    "        print j\n",
    "        clf = GradientBoostingClassifier(max_depth=max_depth, random_state=x_random_states[j],\n",
    "                                         min_samples_split=min_samples_split,learning_rate=learning_rate,\n",
    "                                         n_estimators=n_estimators,verbose=verbose)    \n",
    "        clf.fit(df_train[feats],df_train[label])\n",
    "        gbdt_models.append(clf)\n",
    "#         prob = clf.predict_proba(df_test[feats])\n",
    "#         data_rea['GBDT_%d_PROB' % (j)] = prob\n",
    "    \n",
    "    return gbdt_models\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_xgb(df_train, feats, label):\n",
    "    '''\n",
    "    stacking的第一层，使用15个不同的seed得到15维特征，返回15个模型\n",
    "    \n",
    "    '''\n",
    "    seed = 17\n",
    "    np.random.seed(seed)\n",
    "    param = {'max_depth':3, # 基准是5 \n",
    "         'eta':0.05,\n",
    "         'gamma ':0.1,\n",
    "         'colsample_bytree':0.85, # old 0.8\n",
    "         'subsample':0.85,\n",
    "         'silent':1,\n",
    "         'eval_metric':'auc',\n",
    "         'objective':'binary:logistic',\n",
    "        }\n",
    "\n",
    "    nround = 150 # 参数求的\n",
    "    xgb_models = []\n",
    "    seeds = [71,73,91,101,2017,2018,2019,2020,10003,100007,100009,20003,200005,12345,123456]\n",
    "    for i in range(len(seeds)):\n",
    "        print('LOOP',i)\n",
    "        dbuild, dvalid, watchlist = split_train_valid(df_train, feats, test_size=0.002)\n",
    "        param['seed'] = seeds[i]\n",
    "        model = xgb.train(param, dbuild, nround, watchlist,verbose_eval=20)\n",
    "        xgb_models.append(model)\n",
    "        del dbuild, dvalid, watchlist\n",
    "        \n",
    "    return xgb_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_xgb_second(df_train, feats, label):\n",
    "    '''\n",
    "    stacking的第一层，使用15个不同的seed得到15维特征，返回15个模型\n",
    "    \n",
    "    '''\n",
    "    seed = 17\n",
    "    np.random.seed(seed)\n",
    "    param = {'max_depth':3, # 基准是5 \n",
    "         'eta':0.05,\n",
    "         'gamma ':0.1,\n",
    "         'colsample_bytree':0.85, # old 0.8\n",
    "         'subsample':0.85,\n",
    "         'silent':1,\n",
    "         'eval_metric':'auc',\n",
    "         'objective':'binary:logistic',\n",
    "        }\n",
    "    \n",
    "    nround = 100 # 参数求的\n",
    "    xgb_models = []\n",
    "    seeds = [71,73,91]\n",
    "    for i in range(len(seeds)):\n",
    "        print('LOOP',i)\n",
    "        dbuild, dvalid, watchlist = split_train_valid(df_train,feats,label=label, test_size=0.002)\n",
    "        param['seed'] = seeds[i]\n",
    "        model = xgb.train(param, dbuild, nround, watchlist,verbose_eval=20)\n",
    "        xgb_models.append(model)\n",
    "        del dbuild, dvalid, watchlist\n",
    "        \n",
    "    return xgb_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_models(df_train, feats, label='label'):\n",
    "    rf_models = get_x_rf(df_train, feats, label)\n",
    "    gbdt_models = get_x_gbdt(df_train, feats, label)\n",
    "    \n",
    "    rf_models = []\n",
    "    gbdt_models = []\n",
    "    \n",
    "    \n",
    "    xgb_models = get_x_xgb(df_train, feats, label)\n",
    "    \n",
    "#     return rf_models, gbdt_models, xgb_models  \n",
    "    return rf_models, gbdt_models, xgb_models\n",
    "\n",
    "def one_models_predict(df_data, feats, models, model_type):\n",
    "    data = {'uid':df_data['uid']}\n",
    "    for i in range(len(models)):\n",
    "        if model_type == 'rf':\n",
    "            prob = models[i].predeict(df_data[feats])\n",
    "            data['rf_%d_prob' % i] = prob\n",
    "        elif model_type == 'gbdt':\n",
    "            prob = models[i].predeict(df_data[feats])\n",
    "            data['gbdt_%d_prob' % i] = prob\n",
    "        else:\n",
    "            prob = models[i].predict(xgb.DMatrix(df_data[feats]))\n",
    "            data['xgb_%d_prob' % i] = prob\n",
    "    \n",
    "    return pd.DataFrame(data=data)\n",
    "    \n",
    "\n",
    "def models_predict(rf_models, gbdt_models, xgb_models, df_data, feats):\n",
    "    '''\n",
    "    注意参数的顺序\n",
    "    '''\n",
    "    df_data = one_models_predict(df_data, feats, rf_models, 'xgb')\n",
    "#     df_data = pd.merge(df_data, one_models_predict(df_data, feats, gbdt_models, 'gbdt'))\n",
    "#     df_data = pd.merge(df_data, one_models_predict(df_data, feats, xgb_models, 'xgb'))\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "def models_predict_x(xgb_models, df_data, feats):\n",
    "    '''\n",
    "    注意参数的顺序\n",
    "    '''\n",
    "    df_data = one_models_predict(df_data, feats, xgb_models, 'xgb')\n",
    "#     df_data = pd.merge(df_data, one_models_predict(df_data, feats, gbdt_models, 'gbdt'))\n",
    "#     df_data = pd.merge(df_data, one_models_predict(df_data, feats, xgb_models, 'xgb'))\n",
    "    \n",
    "    return df_data\n",
    "\n",
    "\n",
    "def get_finall_model(df_train_A, df_train_B, feats, label='label'):\n",
    "    \n",
    "#     rf_models, gbdt_models, xgb_models = get_all_models(df_train_A, feats, label)\n",
    "    xgb_models = get_x_xgb(df_train_A, feats, label)\n",
    "    \n",
    "    print len(xgb_models)\n",
    "#     df_train_b = models_predict(rf_models, gbdt_models, xgb_models, df_train_B, feats)\n",
    "    df_train_b = one_models_predict(df_train_B, feats, xgb_models, 'xgb')\n",
    "    df_train_b['label'] = df_train_B['label']\n",
    "    \n",
    "    print df_train_b.info()\n",
    "    \n",
    "    feats_b = list(df_train_b.columns)\n",
    "    if 'uid' in feats_b:\n",
    "        feats_b.remove('uid')\n",
    "    \n",
    "    print \"xgb_model final %d\" % len(xgb_models)\n",
    "    xgb_second_models = get_x_xgb_second(df_train_b, feats_b, label)\n",
    "    \n",
    "    return xgb_models, xgb_second_models\n",
    "\n",
    "\n",
    "def get_finall_score(xgb_second_models, df_test, feats, threold=0.3):\n",
    "    LOOP = len(xgb_second_models)\n",
    "    dtest  = xgb.DMatrix(df_test[feats])\n",
    "    proba_test = pd.DataFrame()\n",
    "    proba_test['uid'] = df_test['uid']\n",
    "    proba_test['score'] = [0 for i in range(len(df_test))]\n",
    "    for model in xgb_second_models:\n",
    "        proba_test['score'] += model.predict(dtest)\n",
    "    proba_test['score'] /= LOOP\n",
    "\n",
    "    proba_test = proba_test.sort_values('score',ascending=False)\n",
    "    proba_test['label'] = [0 for i in range(len(proba_test))]\n",
    "\n",
    "    proba_test.loc[proba_test['score']>threold, 'label'] = 1\n",
    "#     proba_test[['uid','label']].to_csv('../result/xresult_finall_1.csv',index=False,header=False)\n",
    "    \n",
    "    return proba_test\n",
    "\n",
    "def predict_test(df_train_A, df_train_B, df_test, feats, label='label'):\n",
    "    xgb_models, xgb_second_models = get_finall_model(df_train_A, df_train_B, feats, label)\n",
    "    \n",
    "#     print \"rf_models length = %d \" % len(rf_models)\n",
    "#     print \"gbdt_models length = %d \" % len(gbdt_models)\n",
    "    print \"xgb_models length = %d \" % len(xgb_models)\n",
    "    \n",
    "    df_test_b = models_predict_x(xgb_models, df_test, feats)\n",
    "#     df_test_b['lable'] = df_train_B['label']\n",
    "    \n",
    "    print df_test_b.info()\n",
    "    \n",
    "    feats_b = df_test_b.columns\n",
    "    \n",
    "    proba_test = get_finall_score(xgb_second_models, df_data, feats_b)\n",
    "    \n",
    "    return proba_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(df_train, label='label'):\n",
    "    '''\n",
    "    将数据集分成两部分A和B，A训练第一层model，B训练第二层模型, 2 : 3\n",
    "    写入文件，保证能够重现。\n",
    "    '''\n",
    "    df_train_one = df_train[df_train[label] == 1]\n",
    "    df_train_zero = df_train[df_train[label] == 0]\n",
    "    \n",
    "    df_train_one_A = df_train_one.sample(int(len(df_train_one)*0.6))\n",
    "    df_train_one_B = df_train_one[~df_train_one['uid'].isin(df_train_one_A['uid'])]\n",
    "    \n",
    "    df_train_zero_A = df_train_zero.sample(int(len(df_train_zero)*0.6))\n",
    "    df_train_zero_B = df_train_zero[~df_train_zero['uid'].isin(df_train_zero_A['uid'])]\n",
    "    \n",
    "    df_train_A = df_train_one_A.append(df_train_zero_A)\n",
    "    df_train_B = df_train_one_B.append(df_train_zero_B)\n",
    "    \n",
    "    df_train_A = shuffle(df_train_A)\n",
    "    df_train_B = shuffle(df_train_B)\n",
    "    \n",
    "    df_train_A.to_csv('../sdata/df_train_A.csv',index=False)\n",
    "    df_train_B.to_csv('../sdata/df_train_B.csv',index=False)\n",
    "    \n",
    "    return df_train_A, df_train_B\n",
    "\n",
    "def get_data(add_data=False):\n",
    "    df_train_voice_feat = pd.read_csv('../xdata/df_train_voice_feat.csv')\n",
    "    df_test_voice_feat = pd.read_csv('../xdata/df_testB_voice_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA = pd.read_csv('../xdata/df_testA_label.csv')\n",
    "        df_trainA_voice_feat = pd.read_csv('../xdata/df_testA_voice_feat.csv')\n",
    "        \n",
    "    \n",
    "    df_train_sms_feat = pd.read_csv('../xdata/df_train_sms_feat.csv')\n",
    "    df_test_sms_feat = pd.read_csv('../xdata/df_testB_sms_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA_sms_feat = pd.read_csv('../xdata/df_testA_sms_feat.csv')\n",
    "    \n",
    "    df_train_sms_feat.drop('label',axis=1,inplace=True)\n",
    "    \n",
    "    df_train_wa_feat = pd.read_csv('../xdata/df_train_wa_feat.csv')\n",
    "    df_test_wa_feat = pd.read_csv('../xdata/df_testB_wa_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA_wa_feat = pd.read_csv('../xdata/df_testA_wa_feat.csv')\n",
    "\n",
    "    df_train_wa_feat.drop('label',axis=1,inplace=True)\n",
    "    \n",
    "    df_train_voice_sms_wa_feat = pd.read_csv('../xdata/df_train_voice_sms_wa_feat.csv')\n",
    "    df_test_voice_sms_wa_feat = pd.read_csv('../xdata/df_testB_voice_sms_wa_feat.csv')\n",
    "    if add_data==True:\n",
    "        df_trainA_voice_sms_wa_feat = pd.read_csv('../xdata/df_testA_voice_sms_wa_feat.csv')\n",
    "    \n",
    "#     df_train_voice_sms_wa_feat.drop('label',axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    df_train = pd.merge(df_train_voice_feat, df_train_sms_feat, on='uid', how='left')\n",
    "    df_test = pd.merge(df_test_voice_feat, df_test_sms_feat, on='uid', how='left')\n",
    "    \n",
    "    df_train = pd.merge(df_train, df_train_wa_feat, on='uid', how='left')\n",
    "    df_test = pd.merge(df_test, df_test_wa_feat, on='uid', how='left')\n",
    "    \n",
    "    df_train = pd.merge(df_train, df_train_voice_sms_wa_feat, on='uid', how='left')\n",
    "    df_test = pd.merge(df_test, df_test_voice_sms_wa_feat, on='uid', how='left')\n",
    "    \n",
    "    \n",
    "    if add_data==True:\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_voice_feat, on='uid', how='left')\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_sms_feat, on='uid', how='left')\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_wa_feat, on='uid', how='left')\n",
    "        df_trainA = pd.merge(df_trainA, df_trainA_voice_sms_wa_feat, on='uid', how='left')\n",
    "        \n",
    "#         df_trainA = df_trainA[df_trainA['label']==1]\n",
    "        df_trainA = df_trainA[:66]\n",
    "        df_train = df_train.append(df_trainA)\n",
    "\n",
    "    df_train.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_test.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "\n",
    "    df_train.fillna(0,inplace=True)\n",
    "    df_test.fillna(0,inplace=True)\n",
    "    \n",
    "    df_train.drop('wa_all_wa_name_little_wite',axis=1,inplace=True)\n",
    "    df_train.drop('wa_all_wa_name_many_wite',axis=1,inplace=True)\n",
    "    df_train.drop('wa_all_wa_name_little_wite_risk',axis=1,inplace=True)\n",
    "    df_train.drop('wa_all_wa_name_many_wite_risk',axis=1,inplace=True)\n",
    "\n",
    "    df_test.drop('wa_all_wa_name_little_wite',axis=1,inplace=True)\n",
    "    df_test.drop('wa_all_wa_name_many_wite',axis=1,inplace=True)\n",
    "    df_test.drop('wa_all_wa_name_little_wite_risk',axis=1,inplace=True)\n",
    "    df_test.drop('wa_all_wa_name_many_wite_risk',axis=1,inplace=True)\n",
    "    \n",
    "    \n",
    "    df_train.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_test.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "\n",
    "    df_train.fillna(0,inplace=True)\n",
    "    df_test.fillna(0,inplace=True)\n",
    "    \n",
    "    # 数据分成A和B的两部分\n",
    "    split_data(df_train)\n",
    "    \n",
    "    df_train.to_csv('../sdata/df_train_plus.csv',index=False)\n",
    "    df_test.to_csv('../sdata/df_test_plus.csv',index=False)\n",
    "    \n",
    "    return df_train, df_test\n",
    "\n",
    "    \n",
    "    \n",
    "def split_train_valid(df_train, feats, label='label', test_size=0.2):\n",
    "    '''\n",
    "    k-fold交叉验证,默认k=10\n",
    "    df_train:训练数据\n",
    "    '''\n",
    "    X_train, X_vali, y_train, y_vali = train_test_split(df_train[feats], df_train[label], test_size=test_size, random_state=40000)\n",
    "    #added some parameters\n",
    "    \n",
    "#     dtrain = df_train.iloc[train_list]\n",
    "#     dvali =  df_train.iloc[vali_list]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train,label=y_train)\n",
    "    dvalid = xgb.DMatrix(X_vali,label=y_vali)\n",
    "    watchlist = [(dtrain, 'train'),(dvalid, 'valid')]\n",
    "    \n",
    "    return dtrain, dvalid, watchlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = get_data(add_data=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    df_train_A = pd.read_csv('../sdata/df_train_A.csv')\n",
    "    df_train_B = pd.read_csv('../sdata/df_train_B.csv')\n",
    "    df_test = pd.read_csv('../sdata/df_test.csv')\n",
    "    \n",
    "    df_train_A.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_train_B.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_test.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "\n",
    "    df_train_A.fillna(0,inplace=True)\n",
    "    df_train_B.fillna(0,inplace=True) \n",
    "    df_test.fillna(0,inplace=True)\n",
    "        \n",
    "    feats = list(df_test.columns)\n",
    "    feats.remove('uid')\n",
    "    \n",
    "    df_ans = predict_test(df_train_A, df_train_B, df_test, feats, label='label')\n",
    "    \n",
    "    \n",
    "def run_x():\n",
    "    df_train = pd.read_csv('../sdata/df_train_plus.csv')\n",
    "    df_test = pd.read_csv('../sdata/df_test_plus.csv')\n",
    "    \n",
    "    df_train.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "    df_test.replace([np.inf,-np.inf], 0, inplace=True)\n",
    "\n",
    "    df_train.fillna(0,inplace=True)\n",
    "    df_test.fillna(0,inplace=True)\n",
    "        \n",
    "    feats = list(df_test.columns)\n",
    "    feats.remove('uid')\n",
    "    \n",
    "    print len(feats)\n",
    "    \n",
    "    xgb_models = get_x_xgb(df_train,feats,label='label')\n",
    "    \n",
    "    proba_test = get_finall_score(xgb_models, df_test, feats, threold=0.27)\n",
    "    \n",
    "    proba_test[['uid','label']].to_csv('../result/xresult_finall_x_1.csv',index=False,header=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3336\n",
      "('LOOP', 0)\n",
      "[0]\ttrain-auc:0.841473\tvalid-auc:1\n",
      "[20]\ttrain-auc:0.916286\tvalid-auc:1\n",
      "[40]\ttrain-auc:0.932813\tvalid-auc:1\n",
      "[60]\ttrain-auc:0.944752\tvalid-auc:1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-ed90b626d268>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-4570445dacad>\u001b[0m in \u001b[0;36mrun_x\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mxgb_models\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_x_xgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mproba_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_finall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.27\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-36c3be60fa51>\u001b[0m in \u001b[0;36mget_x_xgb\u001b[0;34m(df_train, feats, label)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mdbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.002\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnround\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mxgb_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mdbuild\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwatchlist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaoran/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaoran/anaconda2/lib/python2.7/site-packages/xgboost/training.pyc\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/xiaoran/anaconda2/lib/python2.7/site-packages/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_x()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2aad49310cbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# np.finfo(np.float32).min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
